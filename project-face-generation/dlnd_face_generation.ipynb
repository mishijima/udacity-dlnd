{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Generation\n",
    "\n",
    "In this project, you'll define and train a DCGAN on a dataset of faces. Your goal is to get a generator network to generate *new* images of faces that look as realistic as possible!\n",
    "\n",
    "The project will be broken down into a series of tasks from **loading in data to defining and training adversarial networks**. At the end of the notebook, you'll be able to visualize the results of your trained Generator to see how it performs; your generated samples should look like fairly realistic faces with small amounts of noise.\n",
    "\n",
    "### Get the Data\n",
    "\n",
    "You'll be using the [CelebFaces Attributes Dataset (CelebA)](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) to train your adversarial networks.\n",
    "\n",
    "This dataset is more complex than the number datasets (like MNIST or SVHN) you've been working with, and so, you should prepare to define deeper networks and train them for a longer time to get good results. It is suggested that you utilize a GPU for training.\n",
    "\n",
    "### Pre-processed Data\n",
    "\n",
    "Since the project's main focus is on building the GANs, we've done *some* of the pre-processing for you. Each of the CelebA images has been cropped to remove parts of the image that don't include a face, then resized down to 64x64x3 NumPy images. Some sample data is show below.\n",
    "\n",
    "<img src='assets/processed_face_data.png' width=60% />\n",
    "\n",
    "> If you are working locally, you can download this data [by clicking here](https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5be7eb6f_processed-celeba-small/processed-celeba-small.zip)\n",
    "\n",
    "This is a zip file that you'll need to extract in the home directory of this notebook for further loading and processing. After extracting the data, you should be left with a directory of data `processed_celeba_small/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can comment out after executing\n",
    "# !unzip processed_celeba_small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'processed_celeba_small/'\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "#import helper\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the CelebA Data\n",
    "\n",
    "The [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset contains over 200,000 celebrity images with annotations. Since you're going to be generating faces, you won't need the annotations, you'll only need the images. Note that these are color images with [3 color channels (RGB)](https://en.wikipedia.org/wiki/Channel_(digital_image)#RGB_Images) each.\n",
    "\n",
    "### Pre-process and Load the Data\n",
    "\n",
    "Since the project's main focus is on building the GANs, we've done *some* of the pre-processing for you. Each of the CelebA images has been cropped to remove parts of the image that don't include a face, then resized down to 64x64x3 NumPy images. This *pre-processed* dataset is a smaller subset of the very large CelebA data.\n",
    "\n",
    "> There are a few other steps that you'll need to **transform** this data and create a **DataLoader**.\n",
    "\n",
    "#### Exercise: Complete the following `get_dataloader` function, such that it satisfies these requirements:\n",
    "\n",
    "* Your images should be square, Tensor images of size `image_size x image_size` in the x and y dimension.\n",
    "* Your function should return a DataLoader that shuffles and batches these Tensor images.\n",
    "\n",
    "#### ImageFolder\n",
    "\n",
    "To create a dataset given a directory of images, it's recommended that you use PyTorch's [ImageFolder](https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder) wrapper, with a root directory `processed_celeba_small/` and data transformation passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size, image_size, data_dir='processed_celeba_small/'):\n",
    "    \"\"\"\n",
    "    Batch the neural network data using DataLoader\n",
    "    :param batch_size: The size of each batch; the number of images in a batch\n",
    "    :param img_size: The square size of the image data (x, y)\n",
    "    :param data_dir: Directory where image data is located\n",
    "    :return: DataLoader with batched data\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement function and return a dataloader\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    img_dataset = datasets.ImageFolder(data_dir, transform)\n",
    "\n",
    "    return DataLoader(dataset=img_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DataLoader\n",
    "\n",
    "#### Exercise: Create a DataLoader `celeba_train_loader` with appropriate hyperparameters.\n",
    "\n",
    "Call the above function and create a dataloader to view images. \n",
    "* You can decide on any reasonable `batch_size` parameter\n",
    "* Your `image_size` **must be** `32`. Resizing the data to a smaller size will make for faster training, while still creating convincing images of faces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function hyperparameters\n",
    "batch_size = 40\n",
    "img_size = 32\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Call your function and get a dataloader\n",
    "celeba_train_loader = get_dataloader(batch_size, img_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can view some images! You should seen square images of somewhat-centered faces.\n",
    "\n",
    "Note: You'll need to convert the Tensor images into a NumPy type and transpose the dimensions to correctly display an image, suggested `imshow` code is below, but it may not be perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1327dcdd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# helper display function\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# obtain one batch of training images\n",
    "dataiter = iter(celeba_train_loader)\n",
    "images, _ = dataiter.next() # _ for no labels\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "plot_size=20\n",
    "for idx in np.arange(plot_size):\n",
    "    ax = fig.add_subplot(2, plot_size/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Pre-process your image data and scale it to a pixel range of -1 to 1\n",
    "\n",
    "You need to do a bit of pre-processing; you know that the output of a `tanh` activated generator will contain pixel values in a range from -1 to 1, and so, we need to rescale our training images to a range of -1 to 1. (Right now, they are in a range from 0-1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the scale function\n",
    "def scale(x, feature_range=(-1, 1)):\n",
    "    ''' Scale takes in an image x and returns that image, scaled\n",
    "       with a feature_range of pixel values from -1 to 1. \n",
    "       This function assumes that the input x is already scaled from 0-1.'''\n",
    "    # assume x is scaled to (0, 1)\n",
    "    # scale to feature_range and return scaled x\n",
    "    return x * 2 - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  tensor(-1.)\n",
      "Max:  tensor(0.9765)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# check scaled range\n",
    "# should be close to -1 to 1\n",
    "img = images[0]\n",
    "scaled_img = scale(img)\n",
    "\n",
    "print('Min: ', scaled_img.min())\n",
    "print('Max: ', scaled_img.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Define the Model\n",
    "\n",
    "A GAN is comprised of two adversarial networks, a discriminator and a generator.\n",
    "\n",
    "## Discriminator\n",
    "\n",
    "Your first task will be to define the discriminator. This is a convolutional classifier like you've built before, only without any maxpooling layers. To deal with this complex data, it's suggested you use a deep network with **normalization**. You are also allowed to create any helper functions that may be useful.\n",
    "\n",
    "#### Exercise: Complete the Discriminator class\n",
    "* The inputs to the discriminator are 32x32x3 tensor images\n",
    "* The output should be a single value that will indicate whether a given image is real or fake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper conv function\n",
    "def conv(in_channels, out_channels, kernel_size, stride=2, padding=1, batch_norm=True):\n",
    "    \"\"\"Creates a convolutional layer, with optional batch normalization.\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    conv_layer = nn.Conv2d(in_channels, out_channels, \n",
    "                           kernel_size, stride, padding, bias=False)\n",
    "    \n",
    "    # append conv layer\n",
    "    layers.append(conv_layer)\n",
    "\n",
    "    if batch_norm:\n",
    "        # append batchnorm layer\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "     \n",
    "    # using Sequential container\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper deconv function\n",
    "def deconv(in_channels, out_channels, kernel_size, stride=2, padding=1, batch_norm=True):\n",
    "    \"\"\"Creates a transposed-convolutional layer, with optional batch normalization.\n",
    "    \"\"\"\n",
    "    # create a sequence of transpose + optional batch norm layers\n",
    "    layers = []\n",
    "    transpose_conv_layer = nn.ConvTranspose2d(in_channels, out_channels, \n",
    "                                              kernel_size, stride, padding, bias=False)\n",
    "    # append transpose convolutional layer\n",
    "    layers.append(transpose_conv_layer)\n",
    "    \n",
    "    if batch_norm:\n",
    "        # append batchnorm layer\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "        \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_dim=32):\n",
    "        \"\"\"\n",
    "        Initialize the Discriminator Module\n",
    "        :param conv_dim: The depth of the first convolutional layer\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # complete init function\n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        # Formula to calculate output size ((w - k + 2p) / s) + 1\n",
    "        # w = input length/height\n",
    "        # k = kernel\n",
    "        # p = padding\n",
    "        # s = stride\n",
    "\n",
    "        # in 32x32\n",
    "        self.conv1 = conv(3, conv_dim, 4, batch_norm=False)\n",
    "        # out 16x16\n",
    "        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n",
    "        # out 8x8\n",
    "        self.conv3 = conv(conv_dim*2, conv_dim*2, kernel_size=3, stride=1)\n",
    "        # out 8x8\n",
    "        \n",
    "        self.conv4 = conv(conv_dim*2, conv_dim*4, 4)\n",
    "        # out 4x4\n",
    "        self.conv5 = conv(conv_dim*4, conv_dim*4, kernel_size=3, stride=1)\n",
    "        # out 4x4\n",
    "        \n",
    "        self.conv6 = conv(conv_dim*4, conv_dim*8, 4)\n",
    "        # out 2x2\n",
    "        self.conv7 = conv(conv_dim*8, conv_dim*8, kernel_size=3, stride=1)\n",
    "        # out 2x2     \n",
    "        \n",
    "        # conv_dim*8 depth of last conv * width * height of the output. It produces 1 value as output\n",
    "        self.fc = nn.Linear(conv_dim*8*2*2, 1)\n",
    "        \n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.25)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param x: The input to the neural network     \n",
    "        :return: Discriminator logits; the output of the neural network\n",
    "        \"\"\"\n",
    "        # define feedforward behavior\n",
    "        out = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = F.leaky_relu(self.conv2(out), 0.2)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = F.leaky_relu(self.conv3(out), 0.2)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = F.leaky_relu(self.conv4(out), 0.2)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = F.leaky_relu(self.conv5(out), 0.2)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = F.leaky_relu(self.conv6(out), 0.2)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = F.leaky_relu(self.conv7(out), 0.2)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # flatten\n",
    "        out = out.view(-1, self.conv_dim*8*2*2)\n",
    "        \n",
    "        # final output layer\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_discriminator(Discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "\n",
    "The generator should upsample an input and generate a *new* image of the same size as our training data `32x32x3`. This should be mostly transpose convolutional layers with normalization applied to the outputs.\n",
    "\n",
    "#### Exercise: Complete the Generator class\n",
    "* The inputs to the generator are vectors of some length `z_size`\n",
    "* The output should be a image of shape `32x32x3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, z_size, conv_dim=32):\n",
    "        \"\"\"\n",
    "        Initialize the Generator Module\n",
    "        :param z_size: The length of the input latent vector, z\n",
    "        :param conv_dim: The depth of the inputs to the *last* transpose convolutional layer\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # complete init function\n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        # first, fully-connected layer\n",
    "        self.fc = nn.Linear(z_size, conv_dim*8*2*2)\n",
    "\n",
    "        # transpose conv layers\n",
    "        self.t_conv1 = deconv(conv_dim*8, conv_dim*4, 4)\n",
    "        self.t_conv2 = deconv(conv_dim*4, conv_dim*2, 4)\n",
    "        self.t_conv3 = deconv(conv_dim*2, conv_dim, 4)\n",
    "        self.t_conv4 = deconv(conv_dim, 3, 4, batch_norm=False)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param x: The input to the neural network     \n",
    "        :return: A 32x32x3 Tensor image as output\n",
    "        \"\"\"\n",
    "        # define feedforward behavior\n",
    "        out = self.fc(x)\n",
    "        out = out.view(-1, self.conv_dim*8, 2, 2)\n",
    "        \n",
    "        # hidden transpose conv layers + relu\n",
    "        out = F.relu(self.t_conv1(out))\n",
    "        out = F.relu(self.t_conv2(out))\n",
    "        out = F.relu(self.t_conv3(out))        \n",
    "        \n",
    "        # last layer + tanh activation\n",
    "        out = self.t_conv4(out)\n",
    "        out = F.tanh(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_generator(Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the weights of your networks\n",
    "\n",
    "To help your models converge, you should initialize the weights of the convolutional and linear layers in your model. From reading the [original DCGAN paper](https://arxiv.org/pdf/1511.06434.pdf), they say:\n",
    "> All weights were initialized from a zero-centered Normal distribution with standard deviation 0.02.\n",
    "\n",
    "So, your next task will be to define a weight initialization function that does just this!\n",
    "\n",
    "You can refer back to the lesson on weight initialization or even consult existing model code, such as that from [the `networks.py` file in CycleGAN Github repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py) to help you complete this function.\n",
    "\n",
    "#### Exercise: Complete the weight initialization function\n",
    "\n",
    "* This should initialize only **convolutional** and **linear** layers\n",
    "* Initialize the weights to a normal distribution, centered around 0, with a standard deviation of 0.02.\n",
    "* The bias terms, if they exist, may be left alone or set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    \"\"\"\n",
    "    Applies initial weights to certain layers in a model .\n",
    "    The weights are taken from a normal distribution \n",
    "    with mean = 0, std dev = 0.02.\n",
    "    :param m: A module or layer in a network    \n",
    "    \"\"\"\n",
    "    # classname will be something like:\n",
    "    # `Conv`, `BatchNorm2d`, `Linear`, etc.\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    # TODO: Apply initial weights to convolutional and linear layers\n",
    "    if classname.find('Linear') != -1:\n",
    "        # Initialize the weights to a normal distribution, centered around 0, with a standard deviation of 0.02.\n",
    "        m.weight.data.uniform_(0.0, 0.02)\n",
    "        # The bias terms, if they exist set to 0.\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "\n",
    "        # The bias terms, if they exist set to 0.\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            m.bias.data.zero_()        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build complete network\n",
    "\n",
    "Define your models' hyperparameters and instantiate the discriminator and generator from the classes defined above. Make sure you've passed in the correct input arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "def build_network(d_conv_dim, g_conv_dim, z_size):\n",
    "    # define discriminator and generator\n",
    "    D = Discriminator(d_conv_dim)\n",
    "    G = Generator(z_size=z_size, conv_dim=g_conv_dim)\n",
    "\n",
    "    # initialize model weights\n",
    "    D.apply(weights_init_normal)\n",
    "    G.apply(weights_init_normal)\n",
    "\n",
    "    print(D)\n",
    "    print()\n",
    "    print(G)\n",
    "    \n",
    "    return D, G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Define model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv6): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv7): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25)\n",
      ")\n",
      "\n",
      "Generator(\n",
      "  (fc): Linear(in_features=100, out_features=4096, bias=True)\n",
      "  (t_conv1): Sequential(\n",
      "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (t_conv2): Sequential(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (t_conv3): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (t_conv4): Sequential(\n",
      "    (0): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model hyperparams\n",
    "d_conv_dim = 32\n",
    "g_conv_dim = 128\n",
    "z_size = 100\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "D, G = build_network(d_conv_dim, g_conv_dim, z_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on GPU\n",
    "\n",
    "Check if you can train on GPU. Here, we'll set this as a boolean variable `train_on_gpu`. Later, you'll be responsible for making sure that \n",
    ">* Models,\n",
    "* Model inputs, and\n",
    "* Loss function arguments\n",
    "\n",
    "Are moved to GPU, where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "# Check for a GPU\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Training on GPU!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Discriminator and Generator Losses\n",
    "\n",
    "Now we need to calculate the losses for both types of adversarial networks.\n",
    "\n",
    "### Discriminator Losses\n",
    "\n",
    "> * For the discriminator, the total loss is the sum of the losses for real and fake images, `d_loss = d_real_loss + d_fake_loss`. \n",
    "* Remember that we want the discriminator to output 1 for real images and 0 for fake images, so we need to set up the losses to reflect that.\n",
    "\n",
    "\n",
    "### Generator Loss\n",
    "\n",
    "The generator loss will look similar only with flipped labels. The generator's goal is to get the discriminator to *think* its generated images are *real*.\n",
    "\n",
    "#### Exercise: Complete real and fake loss functions\n",
    "\n",
    "**You may choose to use either cross entropy or a least squares error loss to complete the following `real_loss` and `fake_loss` functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_loss(D_out, smooth=False):\n",
    "    '''Calculates how close discriminator outputs are to being real.\n",
    "       param, D_out: discriminator logits\n",
    "       return: real loss'''\n",
    "    # how close is the produced output from being \"real\"?\n",
    "    batch_size = D_out.size(0)\n",
    "    # compare logits to real labels\n",
    "    # smooth labels if smooth=True\n",
    "    if smooth:\n",
    "        # smooth, real labels = 0.9\n",
    "        labels = torch.ones(batch_size)*0.9\n",
    "    else:\n",
    "        labels = torch.ones(batch_size) # real labels = 1\n",
    "\n",
    "    if train_on_gpu:\n",
    "        labels = labels.cuda()        \n",
    "        \n",
    "    # numerically stable loss\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # calculate loss\n",
    "    loss = criterion(D_out.squeeze(), labels)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def fake_loss(D_out):\n",
    "    '''Calculates how close discriminator outputs are to being fake.\n",
    "       param, D_out: discriminator logits\n",
    "       return: fake loss'''\n",
    "    # how close is the produced output from being \"false\"?\n",
    "    # compare logits to fake labels\n",
    "    batch_size = D_out.size(0)\n",
    "    labels = torch.zeros(batch_size) # fake labels = 0\n",
    "    \n",
    "    if train_on_gpu:\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # calculate loss\n",
    "    loss = criterion(D_out.squeeze(), labels)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "#### Exercise: Define optimizers for your Discriminator (D) and Generator (G)\n",
    "\n",
    "Define optimizers for your models with appropriate hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# params\n",
    "lr = 0.0001\n",
    "beta1=0.30\n",
    "beta2=0.999 # default value\n",
    "\n",
    "# Create optimizers for the discriminator D and generator G\n",
    "d_optimizer = optim.Adam(D.parameters(), lr, [beta1, beta2])\n",
    "g_optimizer = optim.Adam(G.parameters(), lr, [beta1, beta2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "\n",
    "Training will involve alternating between training the discriminator and the generator. You'll use your functions `real_loss` and `fake_loss` to help you calculate the discriminator losses.\n",
    "\n",
    "* You should train the discriminator by alternating on real and fake images\n",
    "* Then the generator, which tries to trick the discriminator and should have an opposing loss function\n",
    "\n",
    "\n",
    "#### Saving Samples\n",
    "\n",
    "You've been given some code to print out some loss statistics and save some generated \"fake\" samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Complete the training function\n",
    "\n",
    "Keep in mind that, if you've moved your models to GPU, you'll also have to move any model inputs to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for viewing a list of passed in sample images\n",
    "def view_samples(epoch, samples):\n",
    "    fig, axes = plt.subplots(figsize=(16,4), nrows=2, ncols=8, sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
    "        img = img.detach().cpu().numpy()\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        img = ((img + 1)*255 / (2)).astype(np.uint8)\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.reshape((32,32,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workspace_utils import keep_awake\n",
    "\n",
    "def train(D, G, n_epochs, print_every=50, save_path=None):\n",
    "    '''Trains adversarial networks for some number of epochs\n",
    "       param, D: the discriminator network\n",
    "       param, G: the generator network\n",
    "       param, n_epochs: number of epochs to train for\n",
    "       param, print_every: when to print and record the models' losses\n",
    "       return: D and G losses'''\n",
    "    \n",
    "    # initialize tracker for minimum validation loss\n",
    "    g_loss_min = np.Inf\n",
    "    d_loss_min = np.Inf\n",
    "    \n",
    "    # move models to GPU\n",
    "    if train_on_gpu:\n",
    "        D.cuda()\n",
    "        G.cuda()\n",
    "\n",
    "    # keep track of loss and generated, \"fake\" samples\n",
    "    samples = []\n",
    "    losses = []\n",
    "\n",
    "    # Get some fixed data for sampling. These are images that are held\n",
    "    # constant throughout training, and allow us to inspect the model's performance\n",
    "    sample_size=16\n",
    "    fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
    "    fixed_z = torch.from_numpy(fixed_z).float()\n",
    "    # move z to GPU if available\n",
    "    if train_on_gpu:\n",
    "        fixed_z = fixed_z.cuda()\n",
    "\n",
    "    # epoch training loop\n",
    "    for epoch in keep_awake(range(n_epochs)):\n",
    "\n",
    "        # batch training loop\n",
    "        for batch_i, (real_images, _) in enumerate(celeba_train_loader):\n",
    "\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = scale(real_images)\n",
    "\n",
    "            # ===============================================\n",
    "            #         YOUR CODE HERE: TRAIN THE NETWORKS\n",
    "            # ===============================================\n",
    "            \n",
    "            # 1. Train the discriminator on real and fake images\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            # Compute the discriminator losses on real images \n",
    "            if train_on_gpu:\n",
    "                real_images = real_images.cuda()\n",
    "\n",
    "            D_real = D(real_images)\n",
    "            d_real_loss = real_loss(D_real, smooth=True)\n",
    "            \n",
    "            # Generate fake images\n",
    "            z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "            z = torch.from_numpy(z).float()\n",
    "            # move x to GPU, if available\n",
    "            if train_on_gpu:\n",
    "                z = z.cuda()\n",
    "            fake_images = G(z)\n",
    "            \n",
    "            # Compute the discriminator losses on fake images            \n",
    "            D_fake = D(fake_images)\n",
    "            d_fake_loss = fake_loss(D_fake)\n",
    "\n",
    "            # add up loss and perform backprop\n",
    "            d_loss = d_real_loss + d_fake_loss\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # 2. Train the generator with an adversarial loss\n",
    "            g_optimizer.zero_grad()\n",
    "            \n",
    "            # Generate fake images\n",
    "            z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "            z = torch.from_numpy(z).float()\n",
    "            if train_on_gpu:\n",
    "                z = z.cuda()\n",
    "            fake_images = G(z)\n",
    "\n",
    "            # Compute the discriminator losses on fake images \n",
    "            # using flipped labels!\n",
    "            D_fake = D(fake_images)\n",
    "            g_loss = real_loss(D_fake) # use real loss to flip labels\n",
    "\n",
    "            # perform backprop\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            \n",
    "            # ===============================================\n",
    "            #              END OF YOUR CODE\n",
    "            # ===============================================\n",
    "\n",
    "            # Print some loss stats\n",
    "            if batch_i % print_every == 0:\n",
    "                # append discriminator loss and generator loss\n",
    "                losses.append((d_loss.item(), g_loss.item()))\n",
    "                # print discriminator and generator loss\n",
    "                print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
    "                        epoch+1, n_epochs, d_loss.item(), g_loss.item()))\n",
    "\n",
    "        ## AFTER EACH EPOCH##    \n",
    "        # this code assumes your generator is named G, feel free to change the name\n",
    "        # generate and save sample, fake images\n",
    "        G.eval() # for generating samples\n",
    "        samples_z = G(fixed_z)\n",
    "        samples.append(samples_z)\n",
    "        _ = view_samples(-1, samples)\n",
    "        G.train() # back to training mode\n",
    "        \n",
    "        ## save the model if g loss and d loss have decreased\n",
    "        if g_loss <= g_loss_min:\n",
    "            print('Generator loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(\n",
    "                g_loss_min,\n",
    "                g_loss))\n",
    "\n",
    "            torch.save(G.state_dict(), 'model_G.pt')\n",
    "            \n",
    "            g_loss_min = g_loss\n",
    "            \n",
    "        if d_loss <= d_loss_min:\n",
    "            print('Discriminator loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(\n",
    "                d_loss_min,\n",
    "                d_loss))\n",
    "\n",
    "            torch.save(D.state_dict(), 'model_D.pt')\n",
    "            \n",
    "            d_loss_min = d_loss               \n",
    "\n",
    "    # Save training generator samples\n",
    "    with open('train_samples.pkl', 'wb') as f:\n",
    "        pkl.dump(samples, f)\n",
    "        _ = view_samples(-1, samples)\n",
    "    \n",
    "    # finally return losses\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your number of training epochs and train your GAN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [    1/   60] | d_loss: 1.3896 | g_loss: 0.6748\n",
      "Epoch [    1/   60] | d_loss: 1.3674 | g_loss: 0.7163\n",
      "Epoch [    1/   60] | d_loss: 1.3868 | g_loss: 0.7660\n",
      "Epoch [    1/   60] | d_loss: 1.3771 | g_loss: 0.7793\n",
      "Epoch [    1/   60] | d_loss: 1.3777 | g_loss: 0.7951\n",
      "Epoch [    1/   60] | d_loss: 1.3759 | g_loss: 0.7969\n",
      "Epoch [    1/   60] | d_loss: 1.3912 | g_loss: 0.7897\n",
      "Epoch [    1/   60] | d_loss: 1.3780 | g_loss: 0.8034\n",
      "Epoch [    1/   60] | d_loss: 1.3744 | g_loss: 0.7978\n",
      "Epoch [    1/   60] | d_loss: 1.3650 | g_loss: 0.8008\n",
      "Epoch [    1/   60] | d_loss: 1.3767 | g_loss: 0.8082\n",
      "Epoch [    1/   60] | d_loss: 1.3653 | g_loss: 0.7996\n",
      "Epoch [    1/   60] | d_loss: 1.3782 | g_loss: 0.7920\n",
      "Epoch [    1/   60] | d_loss: 1.3789 | g_loss: 0.8202\n",
      "Epoch [    1/   60] | d_loss: 1.3788 | g_loss: 0.7991\n",
      "Epoch [    1/   60] | d_loss: 1.3823 | g_loss: 0.7946\n",
      "Epoch [    1/   60] | d_loss: 1.3766 | g_loss: 0.8003\n",
      "Epoch [    1/   60] | d_loss: 1.3736 | g_loss: 0.7980\n",
      "Epoch [    1/   60] | d_loss: 1.3793 | g_loss: 0.7961\n",
      "Epoch [    1/   60] | d_loss: 1.3798 | g_loss: 0.7900\n",
      "Epoch [    1/   60] | d_loss: 1.3739 | g_loss: 0.7974\n",
      "Epoch [    1/   60] | d_loss: 1.3780 | g_loss: 0.8017\n",
      "Epoch [    1/   60] | d_loss: 1.3764 | g_loss: 0.7976\n",
      "Generator loss decreased (inf --> 0.801501). Saving model ...\n",
      "Discriminator loss decreased (inf --> 1.376334). Saving model ...\n",
      "Epoch [    2/   60] | d_loss: 1.3772 | g_loss: 0.8002\n",
      "Epoch [    2/   60] | d_loss: 1.3775 | g_loss: 0.7982\n",
      "Epoch [    2/   60] | d_loss: 1.3782 | g_loss: 0.7999\n",
      "Epoch [    2/   60] | d_loss: 1.3758 | g_loss: 0.7987\n",
      "Epoch [    2/   60] | d_loss: 1.3767 | g_loss: 0.7973\n",
      "Epoch [    2/   60] | d_loss: 1.3738 | g_loss: 0.7985\n",
      "Epoch [    2/   60] | d_loss: 1.3775 | g_loss: 0.7969\n",
      "Epoch [    2/   60] | d_loss: 1.3757 | g_loss: 0.7982\n",
      "Epoch [    2/   60] | d_loss: 1.3749 | g_loss: 0.7978\n",
      "Epoch [    2/   60] | d_loss: 1.3762 | g_loss: 0.7966\n",
      "Epoch [    2/   60] | d_loss: 1.3760 | g_loss: 0.7964\n",
      "Epoch [    2/   60] | d_loss: 1.3751 | g_loss: 0.7979\n",
      "Epoch [    2/   60] | d_loss: 1.3756 | g_loss: 0.7973\n",
      "Epoch [    2/   60] | d_loss: 1.3756 | g_loss: 0.8009\n",
      "Epoch [    2/   60] | d_loss: 1.3755 | g_loss: 0.7981\n",
      "Epoch [    2/   60] | d_loss: 1.3738 | g_loss: 0.7986\n",
      "Epoch [    2/   60] | d_loss: 1.3753 | g_loss: 0.7976\n",
      "Epoch [    2/   60] | d_loss: 1.3770 | g_loss: 0.7975\n",
      "Epoch [    2/   60] | d_loss: 1.3792 | g_loss: 0.7952\n",
      "Epoch [    2/   60] | d_loss: 1.3767 | g_loss: 0.8002\n",
      "Epoch [    2/   60] | d_loss: 1.3759 | g_loss: 0.7984\n",
      "Epoch [    2/   60] | d_loss: 1.3775 | g_loss: 0.8021\n",
      "Epoch [    2/   60] | d_loss: 1.3734 | g_loss: 0.8003\n",
      "Generator loss decreased (0.801501 --> 0.796961). Saving model ...\n",
      "Discriminator loss decreased (1.376334 --> 1.375695). Saving model ...\n",
      "Epoch [    3/   60] | d_loss: 1.3762 | g_loss: 0.7984\n",
      "Epoch [    3/   60] | d_loss: 1.3770 | g_loss: 0.8007\n",
      "Epoch [    3/   60] | d_loss: 1.3762 | g_loss: 0.7977\n",
      "Epoch [    3/   60] | d_loss: 1.3761 | g_loss: 0.7980\n",
      "Epoch [    3/   60] | d_loss: 1.3781 | g_loss: 0.7962\n",
      "Epoch [    3/   60] | d_loss: 1.3758 | g_loss: 0.7964\n",
      "Epoch [    3/   60] | d_loss: 1.3735 | g_loss: 0.7973\n",
      "Epoch [    3/   60] | d_loss: 1.3760 | g_loss: 0.7974\n",
      "Epoch [    3/   60] | d_loss: 1.3758 | g_loss: 0.7987\n",
      "Epoch [    3/   60] | d_loss: 1.3753 | g_loss: 0.7955\n",
      "Epoch [    3/   60] | d_loss: 1.3768 | g_loss: 0.7990\n",
      "Epoch [    3/   60] | d_loss: 1.3768 | g_loss: 0.7985\n",
      "Epoch [    3/   60] | d_loss: 1.3783 | g_loss: 0.7968\n",
      "Epoch [    3/   60] | d_loss: 1.3768 | g_loss: 0.7967\n",
      "Epoch [    3/   60] | d_loss: 1.3757 | g_loss: 0.8002\n",
      "Epoch [    3/   60] | d_loss: 1.3766 | g_loss: 0.7992\n",
      "Epoch [    3/   60] | d_loss: 1.3763 | g_loss: 0.7983\n",
      "Epoch [    3/   60] | d_loss: 1.3750 | g_loss: 0.7997\n",
      "Epoch [    3/   60] | d_loss: 1.3758 | g_loss: 0.7983\n",
      "Epoch [    3/   60] | d_loss: 1.3767 | g_loss: 0.7984\n",
      "Epoch [    3/   60] | d_loss: 1.3755 | g_loss: 0.7995\n",
      "Epoch [    3/   60] | d_loss: 1.3790 | g_loss: 0.7969\n",
      "Epoch [    3/   60] | d_loss: 1.3760 | g_loss: 0.7979\n",
      "Generator loss decreased (0.796961 --> 0.795705). Saving model ...\n",
      "Discriminator loss decreased (1.375695 --> 1.375437). Saving model ...\n",
      "Epoch [    4/   60] | d_loss: 1.3768 | g_loss: 0.7978\n",
      "Epoch [    4/   60] | d_loss: 1.3770 | g_loss: 0.7989\n",
      "Epoch [    4/   60] | d_loss: 1.3760 | g_loss: 0.7958\n",
      "Epoch [    4/   60] | d_loss: 1.3757 | g_loss: 0.7993\n",
      "Epoch [    4/   60] | d_loss: 1.3772 | g_loss: 0.7995\n",
      "Epoch [    4/   60] | d_loss: 1.3739 | g_loss: 0.7992\n",
      "Epoch [    4/   60] | d_loss: 1.3753 | g_loss: 0.7983\n",
      "Epoch [    4/   60] | d_loss: 1.3772 | g_loss: 0.7984\n",
      "Epoch [    4/   60] | d_loss: 1.3749 | g_loss: 0.7965\n",
      "Epoch [    4/   60] | d_loss: 1.3760 | g_loss: 0.7956\n",
      "Epoch [    4/   60] | d_loss: 1.3735 | g_loss: 0.7970\n",
      "Epoch [    4/   60] | d_loss: 1.3754 | g_loss: 0.7963\n",
      "Epoch [    4/   60] | d_loss: 1.3771 | g_loss: 0.7968\n",
      "Epoch [    4/   60] | d_loss: 1.3775 | g_loss: 0.7988\n",
      "Epoch [    4/   60] | d_loss: 1.3783 | g_loss: 0.8003\n",
      "Epoch [    4/   60] | d_loss: 1.3742 | g_loss: 0.8008\n",
      "Epoch [    4/   60] | d_loss: 1.3760 | g_loss: 0.8020\n",
      "Epoch [    4/   60] | d_loss: 1.3743 | g_loss: 0.7977\n",
      "Epoch [    4/   60] | d_loss: 1.3754 | g_loss: 0.7991\n",
      "Epoch [    4/   60] | d_loss: 1.3739 | g_loss: 0.7977\n",
      "Epoch [    4/   60] | d_loss: 1.3765 | g_loss: 0.7955\n",
      "Epoch [    4/   60] | d_loss: 1.3758 | g_loss: 0.8009\n",
      "Epoch [    4/   60] | d_loss: 1.3772 | g_loss: 0.7973\n",
      "Epoch [    5/   60] | d_loss: 1.3766 | g_loss: 0.7970\n",
      "Epoch [    5/   60] | d_loss: 1.3753 | g_loss: 0.7987\n",
      "Epoch [    5/   60] | d_loss: 1.3749 | g_loss: 0.7974\n",
      "Epoch [    5/   60] | d_loss: 1.3790 | g_loss: 0.8015\n",
      "Epoch [    5/   60] | d_loss: 1.3760 | g_loss: 0.7973\n",
      "Epoch [    5/   60] | d_loss: 1.3767 | g_loss: 0.8000\n",
      "Epoch [    5/   60] | d_loss: 1.3771 | g_loss: 0.7973\n",
      "Epoch [    5/   60] | d_loss: 1.3773 | g_loss: 0.7961\n",
      "Epoch [    5/   60] | d_loss: 1.3779 | g_loss: 0.8020\n",
      "Epoch [    5/   60] | d_loss: 1.3754 | g_loss: 0.7985\n",
      "Epoch [    5/   60] | d_loss: 1.3763 | g_loss: 0.7980\n",
      "Epoch [    5/   60] | d_loss: 1.3749 | g_loss: 0.7976\n",
      "Epoch [    5/   60] | d_loss: 1.3765 | g_loss: 0.7993\n",
      "Epoch [    5/   60] | d_loss: 1.3770 | g_loss: 0.7980\n",
      "Epoch [    5/   60] | d_loss: 1.3747 | g_loss: 0.7995\n",
      "Epoch [    5/   60] | d_loss: 1.3774 | g_loss: 0.7979\n",
      "Epoch [    5/   60] | d_loss: 1.3769 | g_loss: 0.7992\n",
      "Epoch [    5/   60] | d_loss: 1.3766 | g_loss: 0.7988\n",
      "Epoch [    5/   60] | d_loss: 1.3775 | g_loss: 0.7985\n",
      "Epoch [    5/   60] | d_loss: 1.3783 | g_loss: 0.7991\n",
      "Epoch [    5/   60] | d_loss: 1.3755 | g_loss: 0.8006\n",
      "Epoch [    5/   60] | d_loss: 1.3776 | g_loss: 0.7995\n",
      "Epoch [    5/   60] | d_loss: 1.3752 | g_loss: 0.7985\n",
      "Epoch [    6/   60] | d_loss: 1.3755 | g_loss: 0.8001\n",
      "Epoch [    6/   60] | d_loss: 1.3758 | g_loss: 0.7992\n",
      "Epoch [    6/   60] | d_loss: 1.3787 | g_loss: 0.8002\n",
      "Epoch [    6/   60] | d_loss: 1.3753 | g_loss: 0.8005\n",
      "Epoch [    6/   60] | d_loss: 1.3760 | g_loss: 0.7990\n",
      "Epoch [    6/   60] | d_loss: 1.3748 | g_loss: 0.7988\n",
      "Epoch [    6/   60] | d_loss: 1.3766 | g_loss: 0.7984\n",
      "Epoch [    6/   60] | d_loss: 1.3739 | g_loss: 0.7975\n",
      "Epoch [    6/   60] | d_loss: 1.3768 | g_loss: 0.7993\n",
      "Epoch [    6/   60] | d_loss: 1.3765 | g_loss: 0.7986\n",
      "Epoch [    6/   60] | d_loss: 1.3797 | g_loss: 0.7952\n",
      "Epoch [    6/   60] | d_loss: 1.3761 | g_loss: 0.8002\n",
      "Epoch [    6/   60] | d_loss: 1.3746 | g_loss: 0.7950\n",
      "Epoch [    6/   60] | d_loss: 1.3751 | g_loss: 0.8020\n",
      "Epoch [    6/   60] | d_loss: 1.3769 | g_loss: 0.7984\n",
      "Epoch [    6/   60] | d_loss: 1.3770 | g_loss: 0.7994\n",
      "Epoch [    6/   60] | d_loss: 1.3767 | g_loss: 0.7986\n",
      "Epoch [    6/   60] | d_loss: 1.3775 | g_loss: 0.8009\n",
      "Epoch [    6/   60] | d_loss: 1.3759 | g_loss: 0.8010\n",
      "Epoch [    6/   60] | d_loss: 1.3749 | g_loss: 0.7994\n",
      "Epoch [    6/   60] | d_loss: 1.3785 | g_loss: 0.7989\n",
      "Epoch [    6/   60] | d_loss: 1.3743 | g_loss: 0.8004\n",
      "Epoch [    6/   60] | d_loss: 1.3762 | g_loss: 0.7994\n",
      "Epoch [    7/   60] | d_loss: 1.3765 | g_loss: 0.7982\n",
      "Epoch [    7/   60] | d_loss: 1.3755 | g_loss: 0.7990\n",
      "Epoch [    7/   60] | d_loss: 1.3758 | g_loss: 0.7991\n",
      "Epoch [    7/   60] | d_loss: 1.3744 | g_loss: 0.8022\n",
      "Epoch [    7/   60] | d_loss: 1.3770 | g_loss: 0.7994\n",
      "Epoch [    7/   60] | d_loss: 1.3773 | g_loss: 0.7996\n",
      "Epoch [    7/   60] | d_loss: 1.3765 | g_loss: 0.7976\n",
      "Epoch [    7/   60] | d_loss: 1.3780 | g_loss: 0.7974\n",
      "Epoch [    7/   60] | d_loss: 1.3762 | g_loss: 0.8020\n",
      "Epoch [    7/   60] | d_loss: 1.3752 | g_loss: 0.7996\n",
      "Epoch [    7/   60] | d_loss: 1.3771 | g_loss: 0.7973\n",
      "Epoch [    7/   60] | d_loss: 1.3768 | g_loss: 0.8006\n",
      "Epoch [    7/   60] | d_loss: 1.3758 | g_loss: 0.8003\n",
      "Epoch [    7/   60] | d_loss: 1.3751 | g_loss: 0.7986\n",
      "Epoch [    7/   60] | d_loss: 1.3753 | g_loss: 0.7997\n",
      "Epoch [    7/   60] | d_loss: 1.3752 | g_loss: 0.7992\n",
      "Epoch [    7/   60] | d_loss: 1.3757 | g_loss: 0.7987\n",
      "Epoch [    7/   60] | d_loss: 1.3748 | g_loss: 0.8011\n",
      "Epoch [    7/   60] | d_loss: 1.3754 | g_loss: 0.7944\n",
      "Epoch [    7/   60] | d_loss: 1.3767 | g_loss: 0.8021\n",
      "Epoch [    7/   60] | d_loss: 1.3762 | g_loss: 0.7970\n",
      "Epoch [    7/   60] | d_loss: 1.3766 | g_loss: 0.8010\n",
      "Epoch [    7/   60] | d_loss: 1.3745 | g_loss: 0.8020\n",
      "Epoch [    8/   60] | d_loss: 1.3763 | g_loss: 0.8020\n",
      "Epoch [    8/   60] | d_loss: 1.3758 | g_loss: 0.7898\n",
      "Epoch [    8/   60] | d_loss: 1.3745 | g_loss: 0.8016\n",
      "Epoch [    8/   60] | d_loss: 1.3757 | g_loss: 0.7975\n",
      "Epoch [    8/   60] | d_loss: 1.3753 | g_loss: 0.8006\n",
      "Epoch [    8/   60] | d_loss: 1.3763 | g_loss: 0.7998\n",
      "Epoch [    8/   60] | d_loss: 1.3762 | g_loss: 0.8043\n",
      "Epoch [    8/   60] | d_loss: 1.3715 | g_loss: 0.8030\n",
      "Epoch [    8/   60] | d_loss: 1.3773 | g_loss: 0.7981\n",
      "Epoch [    8/   60] | d_loss: 1.3779 | g_loss: 0.7989\n",
      "Epoch [    8/   60] | d_loss: 1.3793 | g_loss: 0.7983\n",
      "Epoch [    8/   60] | d_loss: 1.3736 | g_loss: 0.7947\n",
      "Epoch [    8/   60] | d_loss: 1.3777 | g_loss: 0.7995\n",
      "Epoch [    8/   60] | d_loss: 1.3746 | g_loss: 0.8028\n",
      "Epoch [    8/   60] | d_loss: 1.3742 | g_loss: 0.7953\n",
      "Epoch [    8/   60] | d_loss: 1.3720 | g_loss: 0.7984\n",
      "Epoch [    8/   60] | d_loss: 1.3758 | g_loss: 0.8022\n",
      "Epoch [    8/   60] | d_loss: 1.3791 | g_loss: 0.7961\n",
      "Epoch [    8/   60] | d_loss: 1.3768 | g_loss: 0.8022\n",
      "Epoch [    8/   60] | d_loss: 1.3772 | g_loss: 0.7960\n",
      "Epoch [    8/   60] | d_loss: 1.3756 | g_loss: 0.8019\n",
      "Epoch [    8/   60] | d_loss: 1.3709 | g_loss: 0.7979\n",
      "Epoch [    8/   60] | d_loss: 1.3742 | g_loss: 0.8010\n",
      "Discriminator loss decreased (1.375437 --> 1.373901). Saving model ...\n",
      "Epoch [    9/   60] | d_loss: 1.3783 | g_loss: 0.8043\n",
      "Epoch [    9/   60] | d_loss: 1.3750 | g_loss: 0.8035\n",
      "Epoch [    9/   60] | d_loss: 1.3782 | g_loss: 0.8024\n",
      "Epoch [    9/   60] | d_loss: 1.3757 | g_loss: 0.7997\n",
      "Epoch [    9/   60] | d_loss: 1.3714 | g_loss: 0.7996\n",
      "Epoch [    9/   60] | d_loss: 1.3780 | g_loss: 0.7981\n",
      "Epoch [    9/   60] | d_loss: 1.3762 | g_loss: 0.7971\n",
      "Epoch [    9/   60] | d_loss: 1.3760 | g_loss: 0.7925\n",
      "Epoch [    9/   60] | d_loss: 1.3761 | g_loss: 0.8042\n",
      "Epoch [    9/   60] | d_loss: 1.3763 | g_loss: 0.7990\n",
      "Epoch [    9/   60] | d_loss: 1.3795 | g_loss: 0.7886\n",
      "Epoch [    9/   60] | d_loss: 1.3724 | g_loss: 0.8046\n",
      "Epoch [    9/   60] | d_loss: 1.3770 | g_loss: 0.7999\n",
      "Epoch [    9/   60] | d_loss: 1.3738 | g_loss: 0.7859\n",
      "Epoch [    9/   60] | d_loss: 1.3760 | g_loss: 0.8041\n",
      "Epoch [    9/   60] | d_loss: 1.3743 | g_loss: 0.7998\n",
      "Epoch [    9/   60] | d_loss: 1.3758 | g_loss: 0.7965\n",
      "Epoch [    9/   60] | d_loss: 1.3736 | g_loss: 0.7960\n",
      "Epoch [    9/   60] | d_loss: 1.3733 | g_loss: 0.7930\n",
      "Epoch [    9/   60] | d_loss: 1.3741 | g_loss: 0.8063\n",
      "Epoch [    9/   60] | d_loss: 1.3774 | g_loss: 0.8023\n",
      "Epoch [    9/   60] | d_loss: 1.3786 | g_loss: 0.7956\n",
      "Epoch [    9/   60] | d_loss: 1.3746 | g_loss: 0.8019\n",
      "Epoch [   10/   60] | d_loss: 1.3761 | g_loss: 0.8005\n",
      "Epoch [   10/   60] | d_loss: 1.3755 | g_loss: 0.8004\n",
      "Epoch [   10/   60] | d_loss: 1.3737 | g_loss: 0.8005\n",
      "Epoch [   10/   60] | d_loss: 1.3759 | g_loss: 0.7994\n",
      "Epoch [   10/   60] | d_loss: 1.3698 | g_loss: 0.8077\n",
      "Epoch [   10/   60] | d_loss: 1.3731 | g_loss: 0.8150\n",
      "Epoch [   10/   60] | d_loss: 1.3756 | g_loss: 0.8026\n",
      "Epoch [   10/   60] | d_loss: 1.3834 | g_loss: 0.8083\n",
      "Epoch [   10/   60] | d_loss: 1.3647 | g_loss: 0.8127\n",
      "Epoch [   10/   60] | d_loss: 1.3745 | g_loss: 0.8002\n",
      "Epoch [   10/   60] | d_loss: 1.3780 | g_loss: 0.7982\n",
      "Epoch [   10/   60] | d_loss: 1.3706 | g_loss: 0.7985\n",
      "Epoch [   10/   60] | d_loss: 1.3743 | g_loss: 0.8107\n",
      "Epoch [   10/   60] | d_loss: 1.3710 | g_loss: 0.7867\n",
      "Epoch [   10/   60] | d_loss: 1.3929 | g_loss: 0.8044\n",
      "Epoch [   10/   60] | d_loss: 1.3767 | g_loss: 0.7997\n",
      "Epoch [   10/   60] | d_loss: 1.3700 | g_loss: 0.7851\n",
      "Epoch [   10/   60] | d_loss: 1.3754 | g_loss: 0.8025\n",
      "Epoch [   10/   60] | d_loss: 1.3702 | g_loss: 0.8052\n",
      "Epoch [   10/   60] | d_loss: 1.3811 | g_loss: 0.8162\n",
      "Epoch [   10/   60] | d_loss: 1.3777 | g_loss: 0.8224\n",
      "Epoch [   10/   60] | d_loss: 1.3781 | g_loss: 0.8099\n",
      "Epoch [   10/   60] | d_loss: 1.3801 | g_loss: 0.7795\n",
      "Generator loss decreased (0.795705 --> 0.764001). Saving model ...\n",
      "Discriminator loss decreased (1.373901 --> 1.365405). Saving model ...\n",
      "Epoch [   11/   60] | d_loss: 1.3703 | g_loss: 0.7949\n",
      "Epoch [   11/   60] | d_loss: 1.3817 | g_loss: 0.8046\n",
      "Epoch [   11/   60] | d_loss: 1.3771 | g_loss: 0.7910\n",
      "Epoch [   11/   60] | d_loss: 1.3788 | g_loss: 0.8158\n",
      "Epoch [   11/   60] | d_loss: 1.3794 | g_loss: 0.8142\n",
      "Epoch [   11/   60] | d_loss: 1.3748 | g_loss: 0.8073\n",
      "Epoch [   11/   60] | d_loss: 1.3885 | g_loss: 0.8065\n",
      "Epoch [   11/   60] | d_loss: 1.3791 | g_loss: 0.8248\n",
      "Epoch [   11/   60] | d_loss: 1.3777 | g_loss: 0.7914\n",
      "Epoch [   11/   60] | d_loss: 1.3743 | g_loss: 0.8086\n",
      "Epoch [   11/   60] | d_loss: 1.3718 | g_loss: 0.7897\n",
      "Epoch [   11/   60] | d_loss: 1.3779 | g_loss: 0.8100\n",
      "Epoch [   11/   60] | d_loss: 1.3643 | g_loss: 0.8099\n",
      "Epoch [   11/   60] | d_loss: 1.3689 | g_loss: 0.8012\n",
      "Epoch [   11/   60] | d_loss: 1.3765 | g_loss: 0.8058\n",
      "Epoch [   11/   60] | d_loss: 1.3855 | g_loss: 0.8151\n",
      "Epoch [   11/   60] | d_loss: 1.3682 | g_loss: 0.8019\n",
      "Epoch [   11/   60] | d_loss: 1.3853 | g_loss: 0.8179\n",
      "Epoch [   11/   60] | d_loss: 1.3804 | g_loss: 0.8192\n",
      "Epoch [   11/   60] | d_loss: 1.3638 | g_loss: 0.7976\n",
      "Epoch [   11/   60] | d_loss: 1.3881 | g_loss: 0.7869\n",
      "Epoch [   11/   60] | d_loss: 1.3757 | g_loss: 0.8125\n",
      "Epoch [   11/   60] | d_loss: 1.3721 | g_loss: 0.8107\n",
      "Epoch [   12/   60] | d_loss: 1.3780 | g_loss: 0.8084\n",
      "Epoch [   12/   60] | d_loss: 1.3674 | g_loss: 0.8124\n",
      "Epoch [   12/   60] | d_loss: 1.3755 | g_loss: 0.8063\n",
      "Epoch [   12/   60] | d_loss: 1.3877 | g_loss: 0.7685\n",
      "Epoch [   12/   60] | d_loss: 1.3895 | g_loss: 0.7778\n",
      "Epoch [   12/   60] | d_loss: 1.3735 | g_loss: 0.8163\n",
      "Epoch [   12/   60] | d_loss: 1.3779 | g_loss: 0.7782\n",
      "Epoch [   12/   60] | d_loss: 1.3930 | g_loss: 0.8136\n",
      "Epoch [   12/   60] | d_loss: 1.3617 | g_loss: 0.7739\n",
      "Epoch [   12/   60] | d_loss: 1.3907 | g_loss: 0.8031\n",
      "Epoch [   12/   60] | d_loss: 1.3400 | g_loss: 0.8118\n",
      "Epoch [   12/   60] | d_loss: 1.3676 | g_loss: 0.7923\n",
      "Epoch [   12/   60] | d_loss: 1.3479 | g_loss: 0.8371\n",
      "Epoch [   12/   60] | d_loss: 1.3914 | g_loss: 0.7891\n",
      "Epoch [   12/   60] | d_loss: 1.3783 | g_loss: 0.8066\n",
      "Epoch [   12/   60] | d_loss: 1.3612 | g_loss: 0.8048\n",
      "Epoch [   12/   60] | d_loss: 1.3645 | g_loss: 0.7842\n",
      "Epoch [   12/   60] | d_loss: 1.3632 | g_loss: 0.8303\n",
      "Epoch [   12/   60] | d_loss: 1.3587 | g_loss: 0.8216\n",
      "Epoch [   12/   60] | d_loss: 1.3722 | g_loss: 0.8639\n",
      "Epoch [   12/   60] | d_loss: 1.4043 | g_loss: 0.8566\n",
      "Epoch [   12/   60] | d_loss: 1.3916 | g_loss: 0.8182\n",
      "Epoch [   12/   60] | d_loss: 1.3458 | g_loss: 0.8271\n",
      "Epoch [   13/   60] | d_loss: 1.3526 | g_loss: 0.8569\n",
      "Epoch [   13/   60] | d_loss: 1.3316 | g_loss: 0.7884\n",
      "Epoch [   13/   60] | d_loss: 1.3418 | g_loss: 0.8204\n",
      "Epoch [   13/   60] | d_loss: 1.3085 | g_loss: 0.7760\n",
      "Epoch [   13/   60] | d_loss: 1.3687 | g_loss: 0.8539\n",
      "Epoch [   13/   60] | d_loss: 1.4329 | g_loss: 0.9365\n",
      "Epoch [   13/   60] | d_loss: 1.3408 | g_loss: 0.8838\n",
      "Epoch [   13/   60] | d_loss: 1.3977 | g_loss: 0.7815\n",
      "Epoch [   13/   60] | d_loss: 1.3300 | g_loss: 0.8527\n",
      "Epoch [   13/   60] | d_loss: 1.3292 | g_loss: 0.8939\n",
      "Epoch [   13/   60] | d_loss: 1.3744 | g_loss: 0.8458\n",
      "Epoch [   13/   60] | d_loss: 1.2913 | g_loss: 0.7289\n",
      "Epoch [   13/   60] | d_loss: 1.3828 | g_loss: 0.8004\n",
      "Epoch [   13/   60] | d_loss: 1.4567 | g_loss: 0.9499\n",
      "Epoch [   13/   60] | d_loss: 1.3648 | g_loss: 0.8188\n",
      "Epoch [   13/   60] | d_loss: 1.4106 | g_loss: 0.8821\n",
      "Epoch [   13/   60] | d_loss: 1.3768 | g_loss: 0.8915\n",
      "Epoch [   13/   60] | d_loss: 1.4232 | g_loss: 0.8544\n",
      "Epoch [   13/   60] | d_loss: 1.3608 | g_loss: 0.7769\n",
      "Epoch [   13/   60] | d_loss: 1.3948 | g_loss: 0.8047\n",
      "Epoch [   13/   60] | d_loss: 1.3612 | g_loss: 0.7876\n",
      "Epoch [   13/   60] | d_loss: 1.3078 | g_loss: 0.8550\n",
      "Epoch [   13/   60] | d_loss: 1.3005 | g_loss: 0.9178\n",
      "Generator loss decreased (0.764001 --> 0.728437). Saving model ...\n",
      "Discriminator loss decreased (1.365405 --> 1.327347). Saving model ...\n",
      "Epoch [   14/   60] | d_loss: 1.2985 | g_loss: 0.7627\n",
      "Epoch [   14/   60] | d_loss: 1.2467 | g_loss: 0.8718\n",
      "Epoch [   14/   60] | d_loss: 1.3816 | g_loss: 0.8864\n",
      "Epoch [   14/   60] | d_loss: 1.3598 | g_loss: 0.8119\n",
      "Epoch [   14/   60] | d_loss: 1.3055 | g_loss: 0.9216\n",
      "Epoch [   14/   60] | d_loss: 1.5371 | g_loss: 0.9011\n",
      "Epoch [   14/   60] | d_loss: 1.2990 | g_loss: 0.8487\n",
      "Epoch [   14/   60] | d_loss: 1.4426 | g_loss: 0.7813\n",
      "Epoch [   14/   60] | d_loss: 1.3197 | g_loss: 0.8670\n",
      "Epoch [   14/   60] | d_loss: 1.3941 | g_loss: 0.8833\n",
      "Epoch [   14/   60] | d_loss: 1.4496 | g_loss: 0.8434\n",
      "Epoch [   14/   60] | d_loss: 1.5234 | g_loss: 0.6424\n",
      "Epoch [   14/   60] | d_loss: 1.4513 | g_loss: 0.8472\n",
      "Epoch [   14/   60] | d_loss: 1.6070 | g_loss: 0.9790\n",
      "Epoch [   14/   60] | d_loss: 1.2380 | g_loss: 1.0104\n",
      "Epoch [   14/   60] | d_loss: 1.1707 | g_loss: 0.8995\n",
      "Epoch [   14/   60] | d_loss: 1.4202 | g_loss: 0.7412\n",
      "Epoch [   14/   60] | d_loss: 1.4455 | g_loss: 1.1646\n",
      "Epoch [   14/   60] | d_loss: 1.1250 | g_loss: 0.8880\n",
      "Epoch [   14/   60] | d_loss: 1.2154 | g_loss: 1.0530\n",
      "Epoch [   14/   60] | d_loss: 1.3120 | g_loss: 1.1008\n",
      "Epoch [   14/   60] | d_loss: 1.3534 | g_loss: 0.9261\n",
      "Epoch [   14/   60] | d_loss: 1.5915 | g_loss: 1.0983\n",
      "Generator loss decreased (0.728437 --> 0.613061). Saving model ...\n",
      "Epoch [   15/   60] | d_loss: 1.3823 | g_loss: 0.8733\n",
      "Epoch [   15/   60] | d_loss: 1.5070 | g_loss: 0.7001\n",
      "Epoch [   15/   60] | d_loss: 1.3356 | g_loss: 0.8568\n",
      "Epoch [   15/   60] | d_loss: 1.3618 | g_loss: 0.7260\n",
      "Epoch [   15/   60] | d_loss: 1.5720 | g_loss: 0.7569\n",
      "Epoch [   15/   60] | d_loss: 1.3627 | g_loss: 1.0329\n",
      "Epoch [   15/   60] | d_loss: 1.5874 | g_loss: 1.0846\n",
      "Epoch [   15/   60] | d_loss: 1.1588 | g_loss: 0.7627\n",
      "Epoch [   15/   60] | d_loss: 1.5829 | g_loss: 0.8226\n",
      "Epoch [   15/   60] | d_loss: 1.3323 | g_loss: 0.7279\n",
      "Epoch [   15/   60] | d_loss: 1.3659 | g_loss: 0.7086\n",
      "Epoch [   15/   60] | d_loss: 1.2203 | g_loss: 0.8439\n",
      "Epoch [   15/   60] | d_loss: 1.5215 | g_loss: 0.8578\n",
      "Epoch [   15/   60] | d_loss: 1.3276 | g_loss: 1.0581\n",
      "Epoch [   15/   60] | d_loss: 1.5171 | g_loss: 0.9628\n",
      "Epoch [   15/   60] | d_loss: 1.2233 | g_loss: 1.3098\n",
      "Epoch [   15/   60] | d_loss: 1.1022 | g_loss: 1.1563\n",
      "Epoch [   15/   60] | d_loss: 1.7695 | g_loss: 1.0298\n",
      "Epoch [   15/   60] | d_loss: 1.6483 | g_loss: 1.2317\n",
      "Epoch [   15/   60] | d_loss: 1.1488 | g_loss: 0.8749\n",
      "Epoch [   15/   60] | d_loss: 1.1621 | g_loss: 0.8297\n",
      "Epoch [   15/   60] | d_loss: 1.0754 | g_loss: 1.1793\n",
      "Epoch [   15/   60] | d_loss: 1.6271 | g_loss: 1.1397\n",
      "Discriminator loss decreased (1.327347 --> 1.050040). Saving model ...\n",
      "Epoch [   16/   60] | d_loss: 1.1601 | g_loss: 1.2098\n",
      "Epoch [   16/   60] | d_loss: 1.3415 | g_loss: 1.0135\n",
      "Epoch [   16/   60] | d_loss: 1.4204 | g_loss: 0.3955\n",
      "Epoch [   16/   60] | d_loss: 1.4954 | g_loss: 1.2399\n",
      "Epoch [   16/   60] | d_loss: 1.1102 | g_loss: 1.3459\n",
      "Epoch [   16/   60] | d_loss: 0.9007 | g_loss: 1.1028\n",
      "Epoch [   16/   60] | d_loss: 1.8909 | g_loss: 0.7530\n",
      "Epoch [   16/   60] | d_loss: 1.3433 | g_loss: 0.6993\n",
      "Epoch [   16/   60] | d_loss: 1.3193 | g_loss: 0.6851\n",
      "Epoch [   16/   60] | d_loss: 1.4756 | g_loss: 0.8330\n",
      "Epoch [   16/   60] | d_loss: 1.3412 | g_loss: 1.0383\n",
      "Epoch [   16/   60] | d_loss: 1.3231 | g_loss: 0.7290\n",
      "Epoch [   16/   60] | d_loss: 1.4012 | g_loss: 0.8771\n",
      "Epoch [   16/   60] | d_loss: 1.4441 | g_loss: 0.8987\n",
      "Epoch [   16/   60] | d_loss: 1.2192 | g_loss: 1.1235\n",
      "Epoch [   16/   60] | d_loss: 1.4340 | g_loss: 1.1439\n",
      "Epoch [   16/   60] | d_loss: 0.9743 | g_loss: 0.9650\n",
      "Epoch [   16/   60] | d_loss: 1.4502 | g_loss: 1.1825\n",
      "Epoch [   16/   60] | d_loss: 1.2375 | g_loss: 1.0029\n",
      "Epoch [   16/   60] | d_loss: 0.7496 | g_loss: 1.3615\n",
      "Epoch [   16/   60] | d_loss: 0.9616 | g_loss: 1.1015\n",
      "Epoch [   16/   60] | d_loss: 1.4391 | g_loss: 0.9104\n",
      "Epoch [   16/   60] | d_loss: 1.2806 | g_loss: 1.3910\n",
      "Epoch [   17/   60] | d_loss: 1.2202 | g_loss: 1.1225\n",
      "Epoch [   17/   60] | d_loss: 1.2003 | g_loss: 0.9681\n",
      "Epoch [   17/   60] | d_loss: 1.4857 | g_loss: 0.8354\n",
      "Epoch [   17/   60] | d_loss: 0.8411 | g_loss: 0.7935\n",
      "Epoch [   17/   60] | d_loss: 1.3018 | g_loss: 0.8590\n",
      "Epoch [   17/   60] | d_loss: 0.8895 | g_loss: 1.0954\n",
      "Epoch [   17/   60] | d_loss: 1.2310 | g_loss: 1.4297\n",
      "Epoch [   17/   60] | d_loss: 1.6038 | g_loss: 0.8923\n",
      "Epoch [   17/   60] | d_loss: 1.4597 | g_loss: 0.8405\n",
      "Epoch [   17/   60] | d_loss: 1.6144 | g_loss: 1.3573\n",
      "Epoch [   17/   60] | d_loss: 0.7692 | g_loss: 0.8965\n",
      "Epoch [   17/   60] | d_loss: 1.0164 | g_loss: 1.2015\n",
      "Epoch [   17/   60] | d_loss: 1.3583 | g_loss: 1.4929\n",
      "Epoch [   17/   60] | d_loss: 1.4884 | g_loss: 1.2930\n",
      "Epoch [   17/   60] | d_loss: 1.2213 | g_loss: 0.7692\n",
      "Epoch [   17/   60] | d_loss: 1.1091 | g_loss: 0.7452\n",
      "Epoch [   17/   60] | d_loss: 1.1190 | g_loss: 0.7799\n",
      "Epoch [   17/   60] | d_loss: 1.5127 | g_loss: 0.6602\n",
      "Epoch [   17/   60] | d_loss: 0.9061 | g_loss: 1.2988\n",
      "Epoch [   17/   60] | d_loss: 1.2639 | g_loss: 0.9272\n",
      "Epoch [   17/   60] | d_loss: 1.3045 | g_loss: 1.3821\n",
      "Epoch [   17/   60] | d_loss: 0.9892 | g_loss: 1.4109\n",
      "Epoch [   17/   60] | d_loss: 1.3464 | g_loss: 1.1834\n",
      "Epoch [   18/   60] | d_loss: 1.4396 | g_loss: 0.4315\n",
      "Epoch [   18/   60] | d_loss: 1.4477 | g_loss: 0.7411\n",
      "Epoch [   18/   60] | d_loss: 0.9288 | g_loss: 0.4888\n",
      "Epoch [   18/   60] | d_loss: 1.1084 | g_loss: 1.2729\n",
      "Epoch [   18/   60] | d_loss: 1.2271 | g_loss: 1.0233\n",
      "Epoch [   18/   60] | d_loss: 1.0403 | g_loss: 1.0262\n",
      "Epoch [   18/   60] | d_loss: 1.0943 | g_loss: 1.1864\n",
      "Epoch [   18/   60] | d_loss: 1.4608 | g_loss: 1.3205\n",
      "Epoch [   18/   60] | d_loss: 1.4707 | g_loss: 0.7631\n",
      "Epoch [   18/   60] | d_loss: 1.0365 | g_loss: 0.6339\n",
      "Epoch [   18/   60] | d_loss: 1.1263 | g_loss: 1.2158\n",
      "Epoch [   18/   60] | d_loss: 1.5681 | g_loss: 1.2713\n",
      "Epoch [   18/   60] | d_loss: 2.1867 | g_loss: 1.2025\n",
      "Epoch [   18/   60] | d_loss: 1.1382 | g_loss: 0.9634\n",
      "Epoch [   18/   60] | d_loss: 1.4379 | g_loss: 1.4692\n",
      "Epoch [   18/   60] | d_loss: 1.0577 | g_loss: 1.7468\n",
      "Epoch [   18/   60] | d_loss: 1.1608 | g_loss: 1.4727\n",
      "Epoch [   18/   60] | d_loss: 1.1956 | g_loss: 1.0389\n",
      "Epoch [   18/   60] | d_loss: 0.8839 | g_loss: 1.1825\n",
      "Epoch [   18/   60] | d_loss: 0.8612 | g_loss: 1.2718\n",
      "Epoch [   18/   60] | d_loss: 1.1604 | g_loss: 1.1908\n",
      "Epoch [   18/   60] | d_loss: 1.2840 | g_loss: 1.2348\n",
      "Epoch [   18/   60] | d_loss: 1.3195 | g_loss: 0.9554\n",
      "Epoch [   19/   60] | d_loss: 1.6016 | g_loss: 1.1848\n",
      "Epoch [   19/   60] | d_loss: 1.0790 | g_loss: 0.6652\n",
      "Epoch [   19/   60] | d_loss: 1.1290 | g_loss: 0.4611\n",
      "Epoch [   19/   60] | d_loss: 1.4003 | g_loss: 0.9463\n",
      "Epoch [   19/   60] | d_loss: 1.7075 | g_loss: 1.3922\n",
      "Epoch [   19/   60] | d_loss: 1.1315 | g_loss: 0.3821\n",
      "Epoch [   19/   60] | d_loss: 0.8139 | g_loss: 0.8086\n",
      "Epoch [   19/   60] | d_loss: 1.1150 | g_loss: 1.4704\n",
      "Epoch [   19/   60] | d_loss: 1.1535 | g_loss: 1.1733\n",
      "Epoch [   19/   60] | d_loss: 1.0680 | g_loss: 0.6024\n",
      "Epoch [   19/   60] | d_loss: 0.9891 | g_loss: 0.6687\n",
      "Epoch [   19/   60] | d_loss: 1.4295 | g_loss: 0.8785\n",
      "Epoch [   19/   60] | d_loss: 1.0010 | g_loss: 1.2139\n",
      "Epoch [   19/   60] | d_loss: 1.1290 | g_loss: 0.6991\n",
      "Epoch [   19/   60] | d_loss: 1.5568 | g_loss: 0.9459\n",
      "Epoch [   19/   60] | d_loss: 0.7735 | g_loss: 1.7525\n",
      "Epoch [   19/   60] | d_loss: 1.0863 | g_loss: 1.0030\n",
      "Epoch [   19/   60] | d_loss: 1.0293 | g_loss: 1.4980\n",
      "Epoch [   19/   60] | d_loss: 1.9664 | g_loss: 1.0880\n",
      "Epoch [   19/   60] | d_loss: 1.4135 | g_loss: 0.9094\n",
      "Epoch [   19/   60] | d_loss: 1.1694 | g_loss: 1.4688\n",
      "Epoch [   19/   60] | d_loss: 1.3986 | g_loss: 0.8983\n",
      "Epoch [   19/   60] | d_loss: 1.4367 | g_loss: 1.4576\n",
      "Epoch [   20/   60] | d_loss: 1.0572 | g_loss: 1.0860\n",
      "Epoch [   20/   60] | d_loss: 1.2058 | g_loss: 0.5006\n",
      "Epoch [   20/   60] | d_loss: 1.1301 | g_loss: 1.5607\n",
      "Epoch [   20/   60] | d_loss: 0.9859 | g_loss: 0.9448\n",
      "Epoch [   20/   60] | d_loss: 1.2372 | g_loss: 0.8005\n",
      "Epoch [   20/   60] | d_loss: 1.3348 | g_loss: 1.4798\n",
      "Epoch [   20/   60] | d_loss: 1.6410 | g_loss: 0.9200\n",
      "Epoch [   20/   60] | d_loss: 1.3332 | g_loss: 1.1516\n",
      "Epoch [   20/   60] | d_loss: 0.9230 | g_loss: 1.0985\n",
      "Epoch [   20/   60] | d_loss: 1.7904 | g_loss: 0.9716\n",
      "Epoch [   20/   60] | d_loss: 1.1675 | g_loss: 1.1300\n",
      "Epoch [   20/   60] | d_loss: 1.1395 | g_loss: 1.1891\n",
      "Epoch [   20/   60] | d_loss: 1.7411 | g_loss: 0.6463\n",
      "Epoch [   20/   60] | d_loss: 1.1369 | g_loss: 1.5804\n",
      "Epoch [   20/   60] | d_loss: 1.2750 | g_loss: 1.0568\n",
      "Epoch [   20/   60] | d_loss: 1.1842 | g_loss: 1.6478\n",
      "Epoch [   20/   60] | d_loss: 0.9800 | g_loss: 1.5107\n",
      "Epoch [   20/   60] | d_loss: 0.7115 | g_loss: 1.1011\n",
      "Epoch [   20/   60] | d_loss: 1.0154 | g_loss: 1.4951\n",
      "Epoch [   20/   60] | d_loss: 0.7851 | g_loss: 0.9960\n",
      "Epoch [   20/   60] | d_loss: 0.9310 | g_loss: 1.1412\n",
      "Epoch [   20/   60] | d_loss: 1.5683 | g_loss: 1.3583\n",
      "Epoch [   20/   60] | d_loss: 1.0109 | g_loss: 1.2563\n",
      "Epoch [   21/   60] | d_loss: 1.2906 | g_loss: 0.4926\n",
      "Epoch [   21/   60] | d_loss: 0.6358 | g_loss: 1.8184\n",
      "Epoch [   21/   60] | d_loss: 1.5124 | g_loss: 1.1282\n",
      "Epoch [   21/   60] | d_loss: 0.7051 | g_loss: 1.2761\n",
      "Epoch [   21/   60] | d_loss: 0.9051 | g_loss: 1.6450\n",
      "Epoch [   21/   60] | d_loss: 1.1263 | g_loss: 1.4101\n",
      "Epoch [   21/   60] | d_loss: 1.3029 | g_loss: 1.7358\n",
      "Epoch [   21/   60] | d_loss: 1.2563 | g_loss: 0.8566\n",
      "Epoch [   21/   60] | d_loss: 1.3517 | g_loss: 0.8443\n",
      "Epoch [   21/   60] | d_loss: 1.2481 | g_loss: 1.1207\n",
      "Epoch [   21/   60] | d_loss: 1.7184 | g_loss: 1.5340\n",
      "Epoch [   21/   60] | d_loss: 1.2900 | g_loss: 1.7025\n",
      "Epoch [   21/   60] | d_loss: 1.1756 | g_loss: 1.0974\n",
      "Epoch [   21/   60] | d_loss: 0.7997 | g_loss: 1.2914\n",
      "Epoch [   21/   60] | d_loss: 1.2417 | g_loss: 0.8914\n",
      "Epoch [   21/   60] | d_loss: 1.4842 | g_loss: 1.4108\n",
      "Epoch [   21/   60] | d_loss: 1.2926 | g_loss: 1.2330\n",
      "Epoch [   21/   60] | d_loss: 1.3764 | g_loss: 0.9545\n",
      "Epoch [   21/   60] | d_loss: 1.7125 | g_loss: 1.0621\n",
      "Epoch [   21/   60] | d_loss: 1.6459 | g_loss: 2.0622\n",
      "Epoch [   21/   60] | d_loss: 1.1825 | g_loss: 0.4990\n",
      "Epoch [   21/   60] | d_loss: 1.1700 | g_loss: 0.5037\n",
      "Epoch [   21/   60] | d_loss: 1.6147 | g_loss: 1.1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss decreased (1.050040 --> 0.795339). Saving model ...\n",
      "Epoch [   22/   60] | d_loss: 1.2056 | g_loss: 1.3891\n",
      "Epoch [   22/   60] | d_loss: 1.8718 | g_loss: 1.0200\n",
      "Epoch [   22/   60] | d_loss: 1.6246 | g_loss: 0.6473\n",
      "Epoch [   22/   60] | d_loss: 1.2677 | g_loss: 0.7480\n",
      "Epoch [   22/   60] | d_loss: 0.9667 | g_loss: 1.1282\n",
      "Epoch [   22/   60] | d_loss: 1.4286 | g_loss: 0.7869\n",
      "Epoch [   22/   60] | d_loss: 1.0177 | g_loss: 1.0622\n",
      "Epoch [   22/   60] | d_loss: 0.9506 | g_loss: 1.0853\n",
      "Epoch [   22/   60] | d_loss: 1.3459 | g_loss: 0.8560\n",
      "Epoch [   22/   60] | d_loss: 1.2081 | g_loss: 1.4495\n",
      "Epoch [   22/   60] | d_loss: 1.2645 | g_loss: 0.9998\n",
      "Epoch [   22/   60] | d_loss: 1.5306 | g_loss: 0.4584\n",
      "Epoch [   22/   60] | d_loss: 1.5836 | g_loss: 1.1768\n",
      "Epoch [   22/   60] | d_loss: 1.7007 | g_loss: 1.7924\n",
      "Epoch [   22/   60] | d_loss: 0.8237 | g_loss: 1.4505\n",
      "Epoch [   22/   60] | d_loss: 1.0712 | g_loss: 0.4584\n",
      "Epoch [   22/   60] | d_loss: 0.9678 | g_loss: 1.5353\n",
      "Epoch [   22/   60] | d_loss: 1.0165 | g_loss: 0.9185\n",
      "Epoch [   22/   60] | d_loss: 0.8788 | g_loss: 0.4951\n",
      "Epoch [   22/   60] | d_loss: 0.9042 | g_loss: 1.9064\n",
      "Epoch [   22/   60] | d_loss: 1.3735 | g_loss: 1.2261\n",
      "Epoch [   22/   60] | d_loss: 1.1917 | g_loss: 1.1088\n",
      "Epoch [   22/   60] | d_loss: 0.9614 | g_loss: 1.1427\n",
      "Epoch [   23/   60] | d_loss: 1.6192 | g_loss: 0.7658\n",
      "Epoch [   23/   60] | d_loss: 1.3296 | g_loss: 1.8846\n",
      "Epoch [   23/   60] | d_loss: 1.2444 | g_loss: 1.5065\n",
      "Epoch [   23/   60] | d_loss: 0.9735 | g_loss: 1.5251\n",
      "Epoch [   23/   60] | d_loss: 1.0780 | g_loss: 1.2153\n",
      "Epoch [   23/   60] | d_loss: 1.3667 | g_loss: 0.3890\n",
      "Epoch [   23/   60] | d_loss: 1.2993 | g_loss: 0.8357\n",
      "Epoch [   23/   60] | d_loss: 1.6065 | g_loss: 1.5382\n",
      "Epoch [   23/   60] | d_loss: 1.0625 | g_loss: 1.5228\n",
      "Epoch [   23/   60] | d_loss: 1.7009 | g_loss: 0.6175\n",
      "Epoch [   23/   60] | d_loss: 2.1361 | g_loss: 0.7649\n",
      "Epoch [   23/   60] | d_loss: 0.7186 | g_loss: 1.1802\n",
      "Epoch [   23/   60] | d_loss: 1.3729 | g_loss: 0.8883\n",
      "Epoch [   23/   60] | d_loss: 0.9971 | g_loss: 0.6448\n",
      "Epoch [   23/   60] | d_loss: 1.2175 | g_loss: 1.1983\n",
      "Epoch [   23/   60] | d_loss: 1.2534 | g_loss: 0.5449\n",
      "Epoch [   23/   60] | d_loss: 1.5190 | g_loss: 0.6514\n",
      "Epoch [   23/   60] | d_loss: 0.7209 | g_loss: 0.8281\n",
      "Epoch [   23/   60] | d_loss: 1.4751 | g_loss: 1.1689\n",
      "Epoch [   23/   60] | d_loss: 0.8428 | g_loss: 0.9242\n",
      "Epoch [   23/   60] | d_loss: 1.2370 | g_loss: 0.3780\n",
      "Epoch [   23/   60] | d_loss: 1.5109 | g_loss: 0.8739\n",
      "Epoch [   23/   60] | d_loss: 1.3332 | g_loss: 1.5126\n",
      "Generator loss decreased (0.613061 --> 0.386287). Saving model ...\n",
      "Epoch [   24/   60] | d_loss: 1.1198 | g_loss: 0.5970\n",
      "Epoch [   24/   60] | d_loss: 1.9138 | g_loss: 1.1157\n",
      "Epoch [   24/   60] | d_loss: 1.7266 | g_loss: 1.1205\n",
      "Epoch [   24/   60] | d_loss: 0.8039 | g_loss: 0.7391\n",
      "Epoch [   24/   60] | d_loss: 1.8611 | g_loss: 0.8227\n",
      "Epoch [   24/   60] | d_loss: 1.1408 | g_loss: 1.0885\n",
      "Epoch [   24/   60] | d_loss: 1.6414 | g_loss: 1.8859\n",
      "Epoch [   24/   60] | d_loss: 0.9836 | g_loss: 1.3506\n",
      "Epoch [   24/   60] | d_loss: 1.0795 | g_loss: 0.8213\n",
      "Epoch [   24/   60] | d_loss: 0.7117 | g_loss: 1.3059\n",
      "Epoch [   24/   60] | d_loss: 0.6104 | g_loss: 0.7728\n",
      "Epoch [   24/   60] | d_loss: 1.2760 | g_loss: 1.5334\n",
      "Epoch [   24/   60] | d_loss: 1.2925 | g_loss: 1.6332\n",
      "Epoch [   24/   60] | d_loss: 0.8004 | g_loss: 0.8019\n",
      "Epoch [   24/   60] | d_loss: 0.9600 | g_loss: 0.9203\n",
      "Epoch [   24/   60] | d_loss: 1.1332 | g_loss: 0.8160\n",
      "Epoch [   24/   60] | d_loss: 0.6728 | g_loss: 0.6330\n",
      "Epoch [   24/   60] | d_loss: 1.2809 | g_loss: 1.1620\n",
      "Epoch [   24/   60] | d_loss: 1.3177 | g_loss: 0.4451\n",
      "Epoch [   24/   60] | d_loss: 0.9921 | g_loss: 1.1277\n",
      "Epoch [   24/   60] | d_loss: 1.0969 | g_loss: 0.7285\n",
      "Epoch [   24/   60] | d_loss: 1.1083 | g_loss: 0.9016\n",
      "Epoch [   24/   60] | d_loss: 1.1992 | g_loss: 0.9908\n",
      "Generator loss decreased (0.386287 --> 0.165644). Saving model ...\n",
      "Epoch [   25/   60] | d_loss: 1.1712 | g_loss: 1.1123\n",
      "Epoch [   25/   60] | d_loss: 1.0600 | g_loss: 1.0586\n",
      "Epoch [   25/   60] | d_loss: 1.0616 | g_loss: 1.0572\n",
      "Epoch [   25/   60] | d_loss: 0.7204 | g_loss: 1.6334\n",
      "Epoch [   25/   60] | d_loss: 1.2221 | g_loss: 1.2325\n",
      "Epoch [   25/   60] | d_loss: 1.5510 | g_loss: 0.8390\n",
      "Epoch [   25/   60] | d_loss: 0.5564 | g_loss: 0.7424\n",
      "Epoch [   25/   60] | d_loss: 0.9595 | g_loss: 0.3528\n",
      "Epoch [   25/   60] | d_loss: 1.3578 | g_loss: 1.0331\n",
      "Epoch [   25/   60] | d_loss: 0.9126 | g_loss: 1.1010\n",
      "Epoch [   25/   60] | d_loss: 1.8595 | g_loss: 0.5149\n",
      "Epoch [   25/   60] | d_loss: 0.8582 | g_loss: 1.1094\n",
      "Epoch [   25/   60] | d_loss: 0.7968 | g_loss: 1.2788\n",
      "Epoch [   25/   60] | d_loss: 1.5069 | g_loss: 1.8679\n",
      "Epoch [   25/   60] | d_loss: 0.9626 | g_loss: 1.7344\n",
      "Epoch [   25/   60] | d_loss: 1.2941 | g_loss: 0.7206\n",
      "Epoch [   25/   60] | d_loss: 0.8985 | g_loss: 0.7168\n",
      "Epoch [   25/   60] | d_loss: 1.9558 | g_loss: 1.8226\n",
      "Epoch [   25/   60] | d_loss: 1.2951 | g_loss: 1.1199\n",
      "Epoch [   25/   60] | d_loss: 0.9829 | g_loss: 0.4392\n",
      "Epoch [   25/   60] | d_loss: 1.1684 | g_loss: 1.5087\n",
      "Epoch [   25/   60] | d_loss: 1.2099 | g_loss: 2.2163\n",
      "Epoch [   25/   60] | d_loss: 1.1229 | g_loss: 0.2061\n",
      "Epoch [   26/   60] | d_loss: 1.1898 | g_loss: 0.3915\n",
      "Epoch [   26/   60] | d_loss: 0.9126 | g_loss: 0.9906\n",
      "Epoch [   26/   60] | d_loss: 1.3261 | g_loss: 2.2688\n",
      "Epoch [   26/   60] | d_loss: 1.1876 | g_loss: 1.2645\n",
      "Epoch [   26/   60] | d_loss: 0.9348 | g_loss: 0.8679\n",
      "Epoch [   26/   60] | d_loss: 2.5436 | g_loss: 1.3200\n",
      "Epoch [   26/   60] | d_loss: 1.0556 | g_loss: 1.7488\n",
      "Epoch [   26/   60] | d_loss: 1.1789 | g_loss: 1.6122\n",
      "Epoch [   26/   60] | d_loss: 0.9097 | g_loss: 0.6867\n",
      "Epoch [   26/   60] | d_loss: 1.4045 | g_loss: 0.9785\n",
      "Epoch [   26/   60] | d_loss: 1.0964 | g_loss: 1.0718\n",
      "Epoch [   26/   60] | d_loss: 1.0726 | g_loss: 1.6446\n",
      "Epoch [   26/   60] | d_loss: 1.3510 | g_loss: 0.9074\n",
      "Epoch [   26/   60] | d_loss: 0.7658 | g_loss: 0.9420\n",
      "Epoch [   26/   60] | d_loss: 0.7229 | g_loss: 1.6386\n",
      "Epoch [   26/   60] | d_loss: 0.8541 | g_loss: 0.6059\n",
      "Epoch [   26/   60] | d_loss: 0.9035 | g_loss: 1.4308\n",
      "Epoch [   26/   60] | d_loss: 1.3051 | g_loss: 0.8046\n",
      "Epoch [   26/   60] | d_loss: 1.4950 | g_loss: 0.7474\n",
      "Epoch [   26/   60] | d_loss: 2.8791 | g_loss: 1.3005\n",
      "Epoch [   26/   60] | d_loss: 0.8768 | g_loss: 0.8741\n",
      "Epoch [   26/   60] | d_loss: 0.6317 | g_loss: 0.5890\n",
      "Epoch [   26/   60] | d_loss: 1.3564 | g_loss: 1.7208\n",
      "Epoch [   27/   60] | d_loss: 2.1558 | g_loss: 0.7826\n",
      "Epoch [   27/   60] | d_loss: 1.0112 | g_loss: 1.3040\n",
      "Epoch [   27/   60] | d_loss: 1.3980 | g_loss: 0.8014\n",
      "Epoch [   27/   60] | d_loss: 0.9798 | g_loss: 1.6110\n",
      "Epoch [   27/   60] | d_loss: 1.1314 | g_loss: 0.3924\n",
      "Epoch [   27/   60] | d_loss: 1.9181 | g_loss: 0.7849\n",
      "Epoch [   27/   60] | d_loss: 1.0809 | g_loss: 1.9093\n",
      "Epoch [   27/   60] | d_loss: 0.8649 | g_loss: 0.8393\n",
      "Epoch [   27/   60] | d_loss: 2.0404 | g_loss: 0.9970\n",
      "Epoch [   27/   60] | d_loss: 1.4307 | g_loss: 1.1354\n",
      "Epoch [   27/   60] | d_loss: 0.8781 | g_loss: 1.7587\n",
      "Epoch [   27/   60] | d_loss: 1.3977 | g_loss: 1.4113\n",
      "Epoch [   27/   60] | d_loss: 1.2033 | g_loss: 2.0724\n",
      "Epoch [   27/   60] | d_loss: 1.2847 | g_loss: 1.6169\n",
      "Epoch [   27/   60] | d_loss: 1.2174 | g_loss: 1.4002\n",
      "Epoch [   27/   60] | d_loss: 1.0722 | g_loss: 0.7464\n",
      "Epoch [   27/   60] | d_loss: 1.1781 | g_loss: 1.7962\n",
      "Epoch [   27/   60] | d_loss: 1.1241 | g_loss: 1.2538\n",
      "Epoch [   27/   60] | d_loss: 1.1181 | g_loss: 1.6072\n",
      "Epoch [   27/   60] | d_loss: 0.8526 | g_loss: 1.3505\n",
      "Epoch [   27/   60] | d_loss: 1.2316 | g_loss: 0.3953\n",
      "Epoch [   27/   60] | d_loss: 0.9773 | g_loss: 1.0494\n",
      "Epoch [   27/   60] | d_loss: 0.8824 | g_loss: 1.2027\n",
      "Epoch [   28/   60] | d_loss: 1.2602 | g_loss: 1.5253\n",
      "Epoch [   28/   60] | d_loss: 1.3424 | g_loss: 0.5836\n",
      "Epoch [   28/   60] | d_loss: 1.1139 | g_loss: 0.9322\n",
      "Epoch [   28/   60] | d_loss: 1.4888 | g_loss: 0.8247\n",
      "Epoch [   28/   60] | d_loss: 0.9286 | g_loss: 0.2893\n",
      "Epoch [   28/   60] | d_loss: 1.4254 | g_loss: 0.8737\n",
      "Epoch [   28/   60] | d_loss: 1.2086 | g_loss: 0.4975\n",
      "Epoch [   28/   60] | d_loss: 1.0082 | g_loss: 1.0912\n",
      "Epoch [   28/   60] | d_loss: 0.8611 | g_loss: 1.6483\n",
      "Epoch [   28/   60] | d_loss: 1.1079 | g_loss: 0.8601\n",
      "Epoch [   28/   60] | d_loss: 0.8973 | g_loss: 0.6350\n",
      "Epoch [   28/   60] | d_loss: 0.6416 | g_loss: 0.8164\n",
      "Epoch [   28/   60] | d_loss: 1.3899 | g_loss: 0.7868\n",
      "Epoch [   28/   60] | d_loss: 0.9826 | g_loss: 1.9985\n",
      "Epoch [   28/   60] | d_loss: 1.3603 | g_loss: 0.7765\n",
      "Epoch [   28/   60] | d_loss: 0.5245 | g_loss: 1.3064\n",
      "Epoch [   28/   60] | d_loss: 1.3159 | g_loss: 1.7169\n",
      "Epoch [   28/   60] | d_loss: 0.8906 | g_loss: 0.8716\n",
      "Epoch [   28/   60] | d_loss: 0.9616 | g_loss: 0.5211\n",
      "Epoch [   28/   60] | d_loss: 1.2464 | g_loss: 1.4539\n",
      "Epoch [   28/   60] | d_loss: 1.3815 | g_loss: 1.5764\n",
      "Epoch [   28/   60] | d_loss: 1.5470 | g_loss: 0.7056\n",
      "Epoch [   28/   60] | d_loss: 1.3969 | g_loss: 1.1364\n",
      "Epoch [   29/   60] | d_loss: 1.0235 | g_loss: 1.1225\n",
      "Epoch [   29/   60] | d_loss: 1.5827 | g_loss: 1.1805\n",
      "Epoch [   29/   60] | d_loss: 1.3757 | g_loss: 1.4417\n",
      "Epoch [   29/   60] | d_loss: 0.5534 | g_loss: 1.6999\n",
      "Epoch [   29/   60] | d_loss: 1.0750 | g_loss: 1.0973\n",
      "Epoch [   29/   60] | d_loss: 1.1167 | g_loss: 1.6722\n",
      "Epoch [   29/   60] | d_loss: 0.9574 | g_loss: 1.4867\n",
      "Epoch [   29/   60] | d_loss: 1.9040 | g_loss: 0.6907\n",
      "Epoch [   29/   60] | d_loss: 0.8676 | g_loss: 0.8862\n",
      "Epoch [   29/   60] | d_loss: 1.0650 | g_loss: 0.7863\n",
      "Epoch [   29/   60] | d_loss: 0.9638 | g_loss: 1.2428\n",
      "Epoch [   29/   60] | d_loss: 0.9977 | g_loss: 1.8606\n",
      "Epoch [   29/   60] | d_loss: 0.9100 | g_loss: 1.2906\n",
      "Epoch [   29/   60] | d_loss: 1.1009 | g_loss: 1.6010\n",
      "Epoch [   29/   60] | d_loss: 1.5675 | g_loss: 0.6731\n",
      "Epoch [   29/   60] | d_loss: 0.9452 | g_loss: 0.5665\n",
      "Epoch [   29/   60] | d_loss: 1.4746 | g_loss: 2.4397\n",
      "Epoch [   29/   60] | d_loss: 2.1281 | g_loss: 1.9168\n",
      "Epoch [   29/   60] | d_loss: 1.0747 | g_loss: 1.5859\n",
      "Epoch [   29/   60] | d_loss: 1.5509 | g_loss: 0.2624\n",
      "Epoch [   29/   60] | d_loss: 1.2608 | g_loss: 1.1952\n",
      "Epoch [   29/   60] | d_loss: 1.3415 | g_loss: 0.6989\n",
      "Epoch [   29/   60] | d_loss: 1.3354 | g_loss: 1.6978\n",
      "Epoch [   30/   60] | d_loss: 1.3280 | g_loss: 0.2694\n",
      "Epoch [   30/   60] | d_loss: 0.9204 | g_loss: 1.6509\n",
      "Epoch [   30/   60] | d_loss: 1.8323 | g_loss: 1.4380\n",
      "Epoch [   30/   60] | d_loss: 2.0172 | g_loss: 1.4747\n",
      "Epoch [   30/   60] | d_loss: 1.2700 | g_loss: 0.5215\n",
      "Epoch [   30/   60] | d_loss: 1.0304 | g_loss: 1.3099\n",
      "Epoch [   30/   60] | d_loss: 0.9990 | g_loss: 1.3643\n",
      "Epoch [   30/   60] | d_loss: 1.0434 | g_loss: 1.0150\n",
      "Epoch [   30/   60] | d_loss: 1.2576 | g_loss: 0.6711\n",
      "Epoch [   30/   60] | d_loss: 1.4323 | g_loss: 0.9446\n",
      "Epoch [   30/   60] | d_loss: 1.0828 | g_loss: 1.7925\n",
      "Epoch [   30/   60] | d_loss: 1.0202 | g_loss: 1.1414\n",
      "Epoch [   30/   60] | d_loss: 1.0695 | g_loss: 1.3406\n",
      "Epoch [   30/   60] | d_loss: 0.8761 | g_loss: 0.8541\n",
      "Epoch [   30/   60] | d_loss: 0.8824 | g_loss: 0.5755\n",
      "Epoch [   30/   60] | d_loss: 0.7190 | g_loss: 0.9698\n",
      "Epoch [   30/   60] | d_loss: 1.3332 | g_loss: 1.0818\n",
      "Epoch [   30/   60] | d_loss: 1.2766 | g_loss: 1.1004\n",
      "Epoch [   30/   60] | d_loss: 1.1991 | g_loss: 1.6473\n",
      "Epoch [   30/   60] | d_loss: 1.2765 | g_loss: 1.2314\n",
      "Epoch [   30/   60] | d_loss: 0.7276 | g_loss: 0.8768\n",
      "Epoch [   30/   60] | d_loss: 1.0311 | g_loss: 0.8586\n",
      "Epoch [   30/   60] | d_loss: 1.1176 | g_loss: 1.6688\n",
      "Epoch [   31/   60] | d_loss: 1.2642 | g_loss: 1.3852\n",
      "Epoch [   31/   60] | d_loss: 1.7478 | g_loss: 1.7600\n",
      "Epoch [   31/   60] | d_loss: 1.2370 | g_loss: 1.9439\n",
      "Epoch [   31/   60] | d_loss: 1.1765 | g_loss: 2.0972\n",
      "Epoch [   31/   60] | d_loss: 0.9543 | g_loss: 1.0405\n",
      "Epoch [   31/   60] | d_loss: 1.1324 | g_loss: 0.6862\n",
      "Epoch [   31/   60] | d_loss: 0.8908 | g_loss: 1.2315\n",
      "Epoch [   31/   60] | d_loss: 1.3625 | g_loss: 1.5965\n",
      "Epoch [   31/   60] | d_loss: 0.6926 | g_loss: 1.6453\n",
      "Epoch [   31/   60] | d_loss: 1.5380 | g_loss: 1.5898\n",
      "Epoch [   31/   60] | d_loss: 2.2689 | g_loss: 1.5645\n",
      "Epoch [   31/   60] | d_loss: 1.2285 | g_loss: 1.2879\n",
      "Epoch [   31/   60] | d_loss: 1.1495 | g_loss: 1.1992\n",
      "Epoch [   31/   60] | d_loss: 1.0288 | g_loss: 1.0487\n",
      "Epoch [   31/   60] | d_loss: 1.0031 | g_loss: 1.1662\n",
      "Epoch [   31/   60] | d_loss: 1.2510 | g_loss: 0.8344\n",
      "Epoch [   31/   60] | d_loss: 0.6653 | g_loss: 0.5846\n",
      "Epoch [   31/   60] | d_loss: 1.4781 | g_loss: 0.8686\n",
      "Epoch [   31/   60] | d_loss: 0.9220 | g_loss: 1.1227\n",
      "Epoch [   31/   60] | d_loss: 0.6917 | g_loss: 0.6913\n",
      "Epoch [   31/   60] | d_loss: 1.2510 | g_loss: 1.4316\n",
      "Epoch [   31/   60] | d_loss: 1.2040 | g_loss: 1.1373\n",
      "Epoch [   31/   60] | d_loss: 1.9975 | g_loss: 0.4023\n",
      "Epoch [   32/   60] | d_loss: 1.2747 | g_loss: 1.2199\n",
      "Epoch [   32/   60] | d_loss: 1.7156 | g_loss: 1.4338\n",
      "Epoch [   32/   60] | d_loss: 1.2013 | g_loss: 0.4694\n",
      "Epoch [   32/   60] | d_loss: 1.3707 | g_loss: 0.6714\n",
      "Epoch [   32/   60] | d_loss: 1.1886 | g_loss: 1.1292\n",
      "Epoch [   32/   60] | d_loss: 0.9140 | g_loss: 2.2153\n",
      "Epoch [   32/   60] | d_loss: 1.2554 | g_loss: 1.0566\n",
      "Epoch [   32/   60] | d_loss: 0.8041 | g_loss: 1.1812\n",
      "Epoch [   32/   60] | d_loss: 0.8360 | g_loss: 1.2726\n",
      "Epoch [   32/   60] | d_loss: 1.1297 | g_loss: 1.6278\n",
      "Epoch [   32/   60] | d_loss: 1.5908 | g_loss: 2.3069\n",
      "Epoch [   32/   60] | d_loss: 1.2666 | g_loss: 0.8825\n",
      "Epoch [   32/   60] | d_loss: 1.0458 | g_loss: 0.7928\n",
      "Epoch [   32/   60] | d_loss: 1.7620 | g_loss: 1.1554\n",
      "Epoch [   32/   60] | d_loss: 1.0476 | g_loss: 1.7330\n",
      "Epoch [   32/   60] | d_loss: 0.5852 | g_loss: 0.7516\n",
      "Epoch [   32/   60] | d_loss: 1.0427 | g_loss: 0.7925\n",
      "Epoch [   32/   60] | d_loss: 0.8540 | g_loss: 1.0302\n",
      "Epoch [   32/   60] | d_loss: 0.9882 | g_loss: 0.5280\n",
      "Epoch [   32/   60] | d_loss: 0.8539 | g_loss: 0.4334\n",
      "Epoch [   32/   60] | d_loss: 1.3169 | g_loss: 1.3500\n",
      "Epoch [   32/   60] | d_loss: 1.1083 | g_loss: 1.5936\n",
      "Epoch [   32/   60] | d_loss: 1.5422 | g_loss: 0.7762\n",
      "Epoch [   33/   60] | d_loss: 0.8758 | g_loss: 0.6650\n",
      "Epoch [   33/   60] | d_loss: 1.2967 | g_loss: 1.4752\n",
      "Epoch [   33/   60] | d_loss: 1.4159 | g_loss: 1.4860\n",
      "Epoch [   33/   60] | d_loss: 1.5585 | g_loss: 0.5004\n",
      "Epoch [   33/   60] | d_loss: 1.4622 | g_loss: 0.3603\n",
      "Epoch [   33/   60] | d_loss: 0.6781 | g_loss: 1.6188\n",
      "Epoch [   33/   60] | d_loss: 0.6373 | g_loss: 2.0306\n",
      "Epoch [   33/   60] | d_loss: 0.7909 | g_loss: 0.8533\n",
      "Epoch [   33/   60] | d_loss: 1.0651 | g_loss: 0.7296\n",
      "Epoch [   33/   60] | d_loss: 1.9052 | g_loss: 1.6221\n",
      "Epoch [   33/   60] | d_loss: 1.2880 | g_loss: 1.2658\n",
      "Epoch [   33/   60] | d_loss: 1.2782 | g_loss: 0.5310\n",
      "Epoch [   33/   60] | d_loss: 0.8504 | g_loss: 1.4050\n",
      "Epoch [   33/   60] | d_loss: 0.7402 | g_loss: 0.5769\n",
      "Epoch [   33/   60] | d_loss: 1.6602 | g_loss: 1.0735\n",
      "Epoch [   33/   60] | d_loss: 0.6081 | g_loss: 0.4838\n",
      "Epoch [   33/   60] | d_loss: 1.1186 | g_loss: 0.5373\n",
      "Epoch [   33/   60] | d_loss: 1.1821 | g_loss: 0.8073\n",
      "Epoch [   33/   60] | d_loss: 1.9673 | g_loss: 0.3486\n",
      "Epoch [   33/   60] | d_loss: 1.0469 | g_loss: 0.4211\n",
      "Epoch [   33/   60] | d_loss: 1.1479 | g_loss: 1.6195\n",
      "Epoch [   33/   60] | d_loss: 1.0003 | g_loss: 0.7636\n",
      "Epoch [   33/   60] | d_loss: 1.8125 | g_loss: 1.5795\n",
      "Discriminator loss decreased (0.795339 --> 0.545294). Saving model ...\n",
      "Epoch [   34/   60] | d_loss: 1.0405 | g_loss: 2.2812\n",
      "Epoch [   34/   60] | d_loss: 1.0274 | g_loss: 0.9727\n",
      "Epoch [   34/   60] | d_loss: 1.6757 | g_loss: 1.5930\n",
      "Epoch [   34/   60] | d_loss: 1.5133 | g_loss: 1.6612\n",
      "Epoch [   34/   60] | d_loss: 1.3524 | g_loss: 1.7486\n",
      "Epoch [   34/   60] | d_loss: 0.6256 | g_loss: 1.0158\n",
      "Epoch [   34/   60] | d_loss: 1.0978 | g_loss: 1.0784\n",
      "Epoch [   34/   60] | d_loss: 0.8826 | g_loss: 1.0534\n",
      "Epoch [   34/   60] | d_loss: 1.1341 | g_loss: 2.3404\n",
      "Epoch [   34/   60] | d_loss: 1.8030 | g_loss: 1.2911\n",
      "Epoch [   34/   60] | d_loss: 0.9118 | g_loss: 0.6059\n",
      "Epoch [   34/   60] | d_loss: 1.1470 | g_loss: 1.8109\n",
      "Epoch [   34/   60] | d_loss: 1.8845 | g_loss: 0.7646\n",
      "Epoch [   34/   60] | d_loss: 1.4028 | g_loss: 0.5752\n",
      "Epoch [   34/   60] | d_loss: 1.5504 | g_loss: 1.0616\n",
      "Epoch [   34/   60] | d_loss: 0.7816 | g_loss: 2.4007\n",
      "Epoch [   34/   60] | d_loss: 1.2787 | g_loss: 1.5819\n",
      "Epoch [   34/   60] | d_loss: 1.3959 | g_loss: 1.6149\n",
      "Epoch [   34/   60] | d_loss: 1.3918 | g_loss: 1.8183\n",
      "Epoch [   34/   60] | d_loss: 1.7084 | g_loss: 1.0959\n",
      "Epoch [   34/   60] | d_loss: 0.8606 | g_loss: 0.6663\n",
      "Epoch [   34/   60] | d_loss: 1.2613 | g_loss: 0.9045\n",
      "Epoch [   34/   60] | d_loss: 1.8181 | g_loss: 0.7940\n",
      "Epoch [   35/   60] | d_loss: 0.9336 | g_loss: 1.3806\n",
      "Epoch [   35/   60] | d_loss: 1.4358 | g_loss: 1.7709\n",
      "Epoch [   35/   60] | d_loss: 1.1943 | g_loss: 1.1647\n",
      "Epoch [   35/   60] | d_loss: 0.9470 | g_loss: 1.5788\n",
      "Epoch [   35/   60] | d_loss: 1.1089 | g_loss: 1.1039\n",
      "Epoch [   35/   60] | d_loss: 0.8685 | g_loss: 2.5846\n",
      "Epoch [   35/   60] | d_loss: 1.3337 | g_loss: 0.6966\n",
      "Epoch [   35/   60] | d_loss: 0.7217 | g_loss: 0.8260\n",
      "Epoch [   35/   60] | d_loss: 0.9311 | g_loss: 1.3332\n",
      "Epoch [   35/   60] | d_loss: 1.4865 | g_loss: 0.5346\n",
      "Epoch [   35/   60] | d_loss: 1.2498 | g_loss: 0.3132\n",
      "Epoch [   35/   60] | d_loss: 0.8243 | g_loss: 0.5063\n",
      "Epoch [   35/   60] | d_loss: 1.1655 | g_loss: 0.6086\n",
      "Epoch [   35/   60] | d_loss: 1.2294 | g_loss: 0.3895\n",
      "Epoch [   35/   60] | d_loss: 0.9026 | g_loss: 1.5766\n",
      "Epoch [   35/   60] | d_loss: 1.6474 | g_loss: 0.8713\n",
      "Epoch [   35/   60] | d_loss: 1.2320 | g_loss: 0.9894\n",
      "Epoch [   35/   60] | d_loss: 0.9381 | g_loss: 0.3634\n",
      "Epoch [   35/   60] | d_loss: 0.8129 | g_loss: 0.8077\n",
      "Epoch [   35/   60] | d_loss: 2.0052 | g_loss: 1.5021\n",
      "Epoch [   35/   60] | d_loss: 0.6351 | g_loss: 1.2735\n",
      "Epoch [   35/   60] | d_loss: 1.4071 | g_loss: 1.3085\n",
      "Epoch [   35/   60] | d_loss: 1.0563 | g_loss: 1.5974\n",
      "Epoch [   36/   60] | d_loss: 1.6881 | g_loss: 0.8553\n",
      "Epoch [   36/   60] | d_loss: 0.9672 | g_loss: 1.6700\n",
      "Epoch [   36/   60] | d_loss: 1.8428 | g_loss: 0.6420\n",
      "Epoch [   36/   60] | d_loss: 2.0852 | g_loss: 0.5575\n",
      "Epoch [   36/   60] | d_loss: 1.3841 | g_loss: 1.5297\n",
      "Epoch [   36/   60] | d_loss: 1.7586 | g_loss: 0.5002\n",
      "Epoch [   36/   60] | d_loss: 1.1952 | g_loss: 0.6090\n",
      "Epoch [   36/   60] | d_loss: 1.1563 | g_loss: 1.3718\n",
      "Epoch [   36/   60] | d_loss: 1.0397 | g_loss: 1.3230\n",
      "Epoch [   36/   60] | d_loss: 0.7101 | g_loss: 0.7112\n",
      "Epoch [   36/   60] | d_loss: 1.6774 | g_loss: 2.1402\n",
      "Epoch [   36/   60] | d_loss: 0.7726 | g_loss: 0.5496\n",
      "Epoch [   36/   60] | d_loss: 1.6841 | g_loss: 2.0272\n",
      "Epoch [   36/   60] | d_loss: 1.0104 | g_loss: 1.0011\n",
      "Epoch [   36/   60] | d_loss: 0.8209 | g_loss: 2.0163\n",
      "Epoch [   36/   60] | d_loss: 1.3449 | g_loss: 1.5922\n",
      "Epoch [   36/   60] | d_loss: 1.7261 | g_loss: 0.7781\n",
      "Epoch [   36/   60] | d_loss: 1.3607 | g_loss: 0.6541\n",
      "Epoch [   36/   60] | d_loss: 0.8495 | g_loss: 1.3309\n",
      "Epoch [   36/   60] | d_loss: 1.0812 | g_loss: 0.6330\n",
      "Epoch [   36/   60] | d_loss: 1.0965 | g_loss: 1.0371\n",
      "Epoch [   36/   60] | d_loss: 1.4632 | g_loss: 0.9226\n",
      "Epoch [   36/   60] | d_loss: 0.7755 | g_loss: 1.4143\n",
      "Epoch [   37/   60] | d_loss: 0.8849 | g_loss: 1.6964\n",
      "Epoch [   37/   60] | d_loss: 0.9751 | g_loss: 1.5466\n",
      "Epoch [   37/   60] | d_loss: 1.3039 | g_loss: 0.9558\n",
      "Epoch [   37/   60] | d_loss: 0.8760 | g_loss: 1.6088\n",
      "Epoch [   37/   60] | d_loss: 1.5879 | g_loss: 1.3555\n",
      "Epoch [   37/   60] | d_loss: 0.9865 | g_loss: 0.9825\n",
      "Epoch [   37/   60] | d_loss: 1.3373 | g_loss: 1.2622\n",
      "Epoch [   37/   60] | d_loss: 1.7998 | g_loss: 0.7909\n",
      "Epoch [   37/   60] | d_loss: 0.4813 | g_loss: 1.9008\n",
      "Epoch [   37/   60] | d_loss: 2.1312 | g_loss: 1.2619\n",
      "Epoch [   37/   60] | d_loss: 1.2729 | g_loss: 0.6348\n",
      "Epoch [   37/   60] | d_loss: 1.2127 | g_loss: 1.9762\n",
      "Epoch [   37/   60] | d_loss: 1.5493 | g_loss: 1.1130\n",
      "Epoch [   37/   60] | d_loss: 0.5247 | g_loss: 1.2897\n",
      "Epoch [   37/   60] | d_loss: 1.3039 | g_loss: 1.3839\n",
      "Epoch [   37/   60] | d_loss: 0.8928 | g_loss: 1.6591\n",
      "Epoch [   37/   60] | d_loss: 1.1346 | g_loss: 0.3116\n",
      "Epoch [   37/   60] | d_loss: 0.8803 | g_loss: 1.0562\n",
      "Epoch [   37/   60] | d_loss: 0.9252 | g_loss: 2.0160\n",
      "Epoch [   37/   60] | d_loss: 1.4282 | g_loss: 1.6375\n",
      "Epoch [   37/   60] | d_loss: 0.9072 | g_loss: 0.7284\n",
      "Epoch [   37/   60] | d_loss: 0.8598 | g_loss: 1.3190\n",
      "Epoch [   37/   60] | d_loss: 0.7471 | g_loss: 1.2895\n",
      "Generator loss decreased (0.165644 --> 0.146187). Saving model ...\n",
      "Epoch [   38/   60] | d_loss: 1.0102 | g_loss: 0.2403\n",
      "Epoch [   38/   60] | d_loss: 1.2060 | g_loss: 1.5640\n",
      "Epoch [   38/   60] | d_loss: 1.2316 | g_loss: 1.8426\n",
      "Epoch [   38/   60] | d_loss: 0.8407 | g_loss: 0.7956\n",
      "Epoch [   38/   60] | d_loss: 0.9111 | g_loss: 1.2370\n",
      "Epoch [   38/   60] | d_loss: 0.8753 | g_loss: 0.2833\n",
      "Epoch [   38/   60] | d_loss: 1.8005 | g_loss: 1.0570\n",
      "Epoch [   38/   60] | d_loss: 1.3423 | g_loss: 0.8376\n",
      "Epoch [   38/   60] | d_loss: 0.7545 | g_loss: 0.6951\n",
      "Epoch [   38/   60] | d_loss: 1.4030 | g_loss: 0.3462\n",
      "Epoch [   38/   60] | d_loss: 0.9374 | g_loss: 1.0184\n",
      "Epoch [   38/   60] | d_loss: 0.7071 | g_loss: 2.1033\n",
      "Epoch [   38/   60] | d_loss: 1.6181 | g_loss: 1.3001\n",
      "Epoch [   38/   60] | d_loss: 0.5587 | g_loss: 2.7101\n",
      "Epoch [   38/   60] | d_loss: 1.0334 | g_loss: 0.7402\n",
      "Epoch [   38/   60] | d_loss: 1.2139 | g_loss: 1.6096\n",
      "Epoch [   38/   60] | d_loss: 0.5232 | g_loss: 1.5126\n",
      "Epoch [   38/   60] | d_loss: 1.6829 | g_loss: 0.8787\n",
      "Epoch [   38/   60] | d_loss: 1.2230 | g_loss: 0.2402\n",
      "Epoch [   38/   60] | d_loss: 1.2576 | g_loss: 1.3686\n",
      "Epoch [   38/   60] | d_loss: 0.7598 | g_loss: 1.6192\n",
      "Epoch [   38/   60] | d_loss: 0.8802 | g_loss: 1.8316\n",
      "Epoch [   38/   60] | d_loss: 0.9584 | g_loss: 2.0507\n",
      "Epoch [   39/   60] | d_loss: 1.4269 | g_loss: 0.7552\n",
      "Epoch [   39/   60] | d_loss: 0.5685 | g_loss: 1.1099\n",
      "Epoch [   39/   60] | d_loss: 1.6568 | g_loss: 1.8438\n",
      "Epoch [   39/   60] | d_loss: 0.9006 | g_loss: 1.1091\n",
      "Epoch [   39/   60] | d_loss: 0.5938 | g_loss: 1.1963\n",
      "Epoch [   39/   60] | d_loss: 0.5350 | g_loss: 1.5646\n",
      "Epoch [   39/   60] | d_loss: 0.7151 | g_loss: 0.6838\n",
      "Epoch [   39/   60] | d_loss: 1.3290 | g_loss: 0.5794\n",
      "Epoch [   39/   60] | d_loss: 1.0876 | g_loss: 0.5787\n",
      "Epoch [   39/   60] | d_loss: 1.6124 | g_loss: 0.6371\n",
      "Epoch [   39/   60] | d_loss: 0.9719 | g_loss: 1.0701\n",
      "Epoch [   39/   60] | d_loss: 0.7929 | g_loss: 1.0709\n",
      "Epoch [   39/   60] | d_loss: 1.5632 | g_loss: 1.1282\n",
      "Epoch [   39/   60] | d_loss: 1.0214 | g_loss: 1.1568\n",
      "Epoch [   39/   60] | d_loss: 1.0244 | g_loss: 1.1805\n",
      "Epoch [   39/   60] | d_loss: 1.2308 | g_loss: 1.6786\n",
      "Epoch [   39/   60] | d_loss: 0.7699 | g_loss: 1.6820\n",
      "Epoch [   39/   60] | d_loss: 0.7512 | g_loss: 1.6485\n",
      "Epoch [   39/   60] | d_loss: 1.0080 | g_loss: 1.6687\n",
      "Epoch [   39/   60] | d_loss: 0.8155 | g_loss: 2.1500\n",
      "Epoch [   39/   60] | d_loss: 1.8543 | g_loss: 0.7565\n",
      "Epoch [   39/   60] | d_loss: 0.9823 | g_loss: 0.1585\n",
      "Epoch [   39/   60] | d_loss: 0.8940 | g_loss: 0.5188\n",
      "Epoch [   40/   60] | d_loss: 2.6872 | g_loss: 2.3668\n",
      "Epoch [   40/   60] | d_loss: 0.9566 | g_loss: 1.8706\n",
      "Epoch [   40/   60] | d_loss: 1.4134 | g_loss: 1.6012\n",
      "Epoch [   40/   60] | d_loss: 1.1526 | g_loss: 1.2381\n",
      "Epoch [   40/   60] | d_loss: 1.1548 | g_loss: 2.9230\n",
      "Epoch [   40/   60] | d_loss: 0.7165 | g_loss: 1.1709\n",
      "Epoch [   40/   60] | d_loss: 1.7670 | g_loss: 0.9516\n",
      "Epoch [   40/   60] | d_loss: 0.6502 | g_loss: 1.2284\n",
      "Epoch [   40/   60] | d_loss: 0.8723 | g_loss: 0.3575\n",
      "Epoch [   40/   60] | d_loss: 0.6886 | g_loss: 1.3868\n",
      "Epoch [   40/   60] | d_loss: 0.8240 | g_loss: 2.1066\n",
      "Epoch [   40/   60] | d_loss: 1.0849 | g_loss: 1.4766\n",
      "Epoch [   40/   60] | d_loss: 1.1413 | g_loss: 1.3612\n",
      "Epoch [   40/   60] | d_loss: 0.9932 | g_loss: 0.3861\n",
      "Epoch [   40/   60] | d_loss: 0.5805 | g_loss: 0.8346\n",
      "Epoch [   40/   60] | d_loss: 0.8037 | g_loss: 0.4418\n",
      "Epoch [   40/   60] | d_loss: 1.0415 | g_loss: 0.8732\n",
      "Epoch [   40/   60] | d_loss: 1.0480 | g_loss: 1.9585\n",
      "Epoch [   40/   60] | d_loss: 0.6531 | g_loss: 1.5113\n",
      "Epoch [   40/   60] | d_loss: 0.7409 | g_loss: 1.2342\n",
      "Epoch [   40/   60] | d_loss: 1.3788 | g_loss: 1.3184\n",
      "Epoch [   40/   60] | d_loss: 1.0092 | g_loss: 1.0666\n",
      "Epoch [   40/   60] | d_loss: 1.7476 | g_loss: 1.2059\n",
      "Epoch [   41/   60] | d_loss: 1.9813 | g_loss: 1.1693\n",
      "Epoch [   41/   60] | d_loss: 1.3813 | g_loss: 0.7415\n",
      "Epoch [   41/   60] | d_loss: 0.9344 | g_loss: 1.2764\n",
      "Epoch [   41/   60] | d_loss: 1.0427 | g_loss: 1.0892\n",
      "Epoch [   41/   60] | d_loss: 1.1062 | g_loss: 1.7768\n",
      "Epoch [   41/   60] | d_loss: 1.2444 | g_loss: 0.8081\n",
      "Epoch [   41/   60] | d_loss: 0.9006 | g_loss: 1.2697\n",
      "Epoch [   41/   60] | d_loss: 0.6450 | g_loss: 2.1318\n",
      "Epoch [   41/   60] | d_loss: 1.4769 | g_loss: 1.4339\n",
      "Epoch [   41/   60] | d_loss: 1.3585 | g_loss: 1.1926\n",
      "Epoch [   41/   60] | d_loss: 1.6793 | g_loss: 2.1692\n",
      "Epoch [   41/   60] | d_loss: 0.9927 | g_loss: 0.5777\n",
      "Epoch [   41/   60] | d_loss: 0.6756 | g_loss: 1.3196\n",
      "Epoch [   41/   60] | d_loss: 1.2686 | g_loss: 0.3617\n",
      "Epoch [   41/   60] | d_loss: 0.8903 | g_loss: 0.3584\n",
      "Epoch [   41/   60] | d_loss: 1.3898 | g_loss: 1.1128\n",
      "Epoch [   41/   60] | d_loss: 1.1407 | g_loss: 0.9269\n",
      "Epoch [   41/   60] | d_loss: 1.0411 | g_loss: 0.9084\n",
      "Epoch [   41/   60] | d_loss: 1.2286 | g_loss: 1.6892\n",
      "Epoch [   41/   60] | d_loss: 1.0750 | g_loss: 0.9845\n",
      "Epoch [   41/   60] | d_loss: 0.6800 | g_loss: 1.0612\n",
      "Epoch [   41/   60] | d_loss: 1.5861 | g_loss: 2.3064\n",
      "Epoch [   41/   60] | d_loss: 1.5672 | g_loss: 1.4419\n",
      "Epoch [   42/   60] | d_loss: 2.5100 | g_loss: 0.5473\n",
      "Epoch [   42/   60] | d_loss: 0.8612 | g_loss: 0.4588\n",
      "Epoch [   42/   60] | d_loss: 1.5474 | g_loss: 1.9795\n",
      "Epoch [   42/   60] | d_loss: 1.1024 | g_loss: 0.7105\n",
      "Epoch [   42/   60] | d_loss: 1.0139 | g_loss: 1.6258\n",
      "Epoch [   42/   60] | d_loss: 1.1104 | g_loss: 1.0645\n",
      "Epoch [   42/   60] | d_loss: 0.6685 | g_loss: 2.1767\n",
      "Epoch [   42/   60] | d_loss: 1.3271 | g_loss: 1.3526\n",
      "Epoch [   42/   60] | d_loss: 0.7400 | g_loss: 1.1618\n",
      "Epoch [   42/   60] | d_loss: 1.0390 | g_loss: 1.8434\n",
      "Epoch [   42/   60] | d_loss: 0.9918 | g_loss: 0.5223\n",
      "Epoch [   42/   60] | d_loss: 1.2680 | g_loss: 0.5922\n",
      "Epoch [   42/   60] | d_loss: 1.4503 | g_loss: 1.5020\n",
      "Epoch [   42/   60] | d_loss: 1.2869 | g_loss: 1.4143\n",
      "Epoch [   42/   60] | d_loss: 1.1227 | g_loss: 0.2729\n",
      "Epoch [   42/   60] | d_loss: 1.5064 | g_loss: 2.4490\n",
      "Epoch [   42/   60] | d_loss: 1.3839 | g_loss: 0.7338\n",
      "Epoch [   42/   60] | d_loss: 0.7707 | g_loss: 2.1657\n",
      "Epoch [   42/   60] | d_loss: 1.3584 | g_loss: 1.1142\n",
      "Epoch [   42/   60] | d_loss: 1.5044 | g_loss: 1.4192\n",
      "Epoch [   42/   60] | d_loss: 0.4866 | g_loss: 1.7565\n",
      "Epoch [   42/   60] | d_loss: 1.0557 | g_loss: 0.4861\n",
      "Epoch [   42/   60] | d_loss: 1.0951 | g_loss: 0.4462\n",
      "Epoch [   43/   60] | d_loss: 1.0299 | g_loss: 2.0264\n",
      "Epoch [   43/   60] | d_loss: 1.2593 | g_loss: 1.0260\n",
      "Epoch [   43/   60] | d_loss: 1.7288 | g_loss: 1.5212\n",
      "Epoch [   43/   60] | d_loss: 0.8366 | g_loss: 1.5757\n",
      "Epoch [   43/   60] | d_loss: 1.2260 | g_loss: 1.0664\n",
      "Epoch [   43/   60] | d_loss: 0.9115 | g_loss: 1.6659\n",
      "Epoch [   43/   60] | d_loss: 0.6861 | g_loss: 1.3419\n",
      "Epoch [   43/   60] | d_loss: 0.9344 | g_loss: 0.8289\n",
      "Epoch [   43/   60] | d_loss: 0.8276 | g_loss: 1.0430\n",
      "Epoch [   43/   60] | d_loss: 0.8784 | g_loss: 2.3915\n",
      "Epoch [   43/   60] | d_loss: 0.7183 | g_loss: 2.1741\n",
      "Epoch [   43/   60] | d_loss: 1.5942 | g_loss: 1.6401\n",
      "Epoch [   43/   60] | d_loss: 1.4741 | g_loss: 1.8073\n",
      "Epoch [   43/   60] | d_loss: 1.0163 | g_loss: 1.7265\n",
      "Epoch [   43/   60] | d_loss: 1.2554 | g_loss: 0.6039\n",
      "Epoch [   43/   60] | d_loss: 0.9959 | g_loss: 1.3476\n",
      "Epoch [   43/   60] | d_loss: 1.4760 | g_loss: 1.4668\n",
      "Epoch [   43/   60] | d_loss: 2.2922 | g_loss: 2.2023\n",
      "Epoch [   43/   60] | d_loss: 0.6613 | g_loss: 0.7886\n",
      "Epoch [   43/   60] | d_loss: 0.9183 | g_loss: 1.1323\n",
      "Epoch [   43/   60] | d_loss: 1.1573 | g_loss: 1.5700\n",
      "Epoch [   43/   60] | d_loss: 1.2698 | g_loss: 0.4371\n",
      "Epoch [   43/   60] | d_loss: 0.5758 | g_loss: 1.6715\n",
      "Epoch [   44/   60] | d_loss: 0.7867 | g_loss: 1.2598\n",
      "Epoch [   44/   60] | d_loss: 0.8368 | g_loss: 1.1150\n",
      "Epoch [   44/   60] | d_loss: 0.9981 | g_loss: 0.8802\n",
      "Epoch [   44/   60] | d_loss: 2.4485 | g_loss: 1.4299\n",
      "Epoch [   44/   60] | d_loss: 0.9619 | g_loss: 1.4280\n",
      "Epoch [   44/   60] | d_loss: 1.8544 | g_loss: 1.3911\n",
      "Epoch [   44/   60] | d_loss: 1.2713 | g_loss: 1.0110\n",
      "Epoch [   44/   60] | d_loss: 0.9007 | g_loss: 0.8401\n",
      "Epoch [   44/   60] | d_loss: 1.2980 | g_loss: 2.2200\n",
      "Epoch [   44/   60] | d_loss: 0.6051 | g_loss: 1.1119\n",
      "Epoch [   44/   60] | d_loss: 1.4814 | g_loss: 0.8851\n",
      "Epoch [   44/   60] | d_loss: 0.5863 | g_loss: 0.8037\n",
      "Epoch [   44/   60] | d_loss: 0.5318 | g_loss: 2.2468\n",
      "Epoch [   44/   60] | d_loss: 0.8965 | g_loss: 2.3663\n",
      "Epoch [   44/   60] | d_loss: 1.1280 | g_loss: 1.0710\n",
      "Epoch [   44/   60] | d_loss: 1.1461 | g_loss: 1.4692\n",
      "Epoch [   44/   60] | d_loss: 0.5952 | g_loss: 1.5946\n",
      "Epoch [   44/   60] | d_loss: 1.3068 | g_loss: 1.3570\n",
      "Epoch [   44/   60] | d_loss: 1.8987 | g_loss: 1.7212\n",
      "Epoch [   44/   60] | d_loss: 0.7366 | g_loss: 0.7461\n",
      "Epoch [   44/   60] | d_loss: 1.0131 | g_loss: 1.7993\n",
      "Epoch [   44/   60] | d_loss: 0.6693 | g_loss: 1.1698\n",
      "Epoch [   44/   60] | d_loss: 0.8056 | g_loss: 1.7417\n",
      "Epoch [   45/   60] | d_loss: 1.4385 | g_loss: 0.9855\n",
      "Epoch [   45/   60] | d_loss: 0.8766 | g_loss: 0.6087\n",
      "Epoch [   45/   60] | d_loss: 1.0123 | g_loss: 0.6692\n",
      "Epoch [   45/   60] | d_loss: 1.1325 | g_loss: 1.1959\n",
      "Epoch [   45/   60] | d_loss: 0.7574 | g_loss: 0.3860\n",
      "Epoch [   45/   60] | d_loss: 1.9461 | g_loss: 1.6760\n",
      "Epoch [   45/   60] | d_loss: 0.6814 | g_loss: 1.4795\n",
      "Epoch [   45/   60] | d_loss: 1.0627 | g_loss: 0.4353\n",
      "Epoch [   45/   60] | d_loss: 1.2996 | g_loss: 1.1873\n",
      "Epoch [   45/   60] | d_loss: 2.5747 | g_loss: 0.5470\n",
      "Epoch [   45/   60] | d_loss: 0.8744 | g_loss: 1.1202\n",
      "Epoch [   45/   60] | d_loss: 1.0766 | g_loss: 2.7727\n",
      "Epoch [   45/   60] | d_loss: 1.0658 | g_loss: 1.5698\n",
      "Epoch [   45/   60] | d_loss: 1.7314 | g_loss: 0.4204\n",
      "Epoch [   45/   60] | d_loss: 0.9897 | g_loss: 1.9715\n",
      "Epoch [   45/   60] | d_loss: 0.4259 | g_loss: 0.6304\n",
      "Epoch [   45/   60] | d_loss: 1.5207 | g_loss: 0.7233\n",
      "Epoch [   45/   60] | d_loss: 1.4208 | g_loss: 0.5520\n",
      "Epoch [   45/   60] | d_loss: 0.8447 | g_loss: 0.3943\n",
      "Epoch [   45/   60] | d_loss: 1.1505 | g_loss: 0.3439\n",
      "Epoch [   45/   60] | d_loss: 0.4655 | g_loss: 1.9908\n",
      "Epoch [   45/   60] | d_loss: 1.2132 | g_loss: 0.8359\n",
      "Epoch [   45/   60] | d_loss: 0.8288 | g_loss: 0.9129\n",
      "Epoch [   46/   60] | d_loss: 1.0894 | g_loss: 1.6878\n",
      "Epoch [   46/   60] | d_loss: 1.4624 | g_loss: 0.5139\n",
      "Epoch [   46/   60] | d_loss: 1.0299 | g_loss: 1.5447\n",
      "Epoch [   46/   60] | d_loss: 1.2405 | g_loss: 1.2022\n",
      "Epoch [   46/   60] | d_loss: 0.8290 | g_loss: 1.0226\n",
      "Epoch [   46/   60] | d_loss: 0.9842 | g_loss: 2.1557\n",
      "Epoch [   46/   60] | d_loss: 1.1106 | g_loss: 1.4524\n",
      "Epoch [   46/   60] | d_loss: 1.1648 | g_loss: 1.4708\n",
      "Epoch [   46/   60] | d_loss: 0.8651 | g_loss: 2.7848\n",
      "Epoch [   46/   60] | d_loss: 0.9148 | g_loss: 2.3759\n",
      "Epoch [   46/   60] | d_loss: 0.7458 | g_loss: 0.6101\n",
      "Epoch [   46/   60] | d_loss: 1.9418 | g_loss: 3.1521\n",
      "Epoch [   46/   60] | d_loss: 0.7388 | g_loss: 1.9003\n",
      "Epoch [   46/   60] | d_loss: 0.7358 | g_loss: 1.0727\n",
      "Epoch [   46/   60] | d_loss: 0.5381 | g_loss: 2.2113\n",
      "Epoch [   46/   60] | d_loss: 2.3608 | g_loss: 0.7586\n",
      "Epoch [   46/   60] | d_loss: 0.7339 | g_loss: 1.0724\n",
      "Epoch [   46/   60] | d_loss: 1.9003 | g_loss: 0.9084\n",
      "Epoch [   46/   60] | d_loss: 1.1168 | g_loss: 1.8178\n",
      "Epoch [   46/   60] | d_loss: 0.6398 | g_loss: 1.5304\n",
      "Epoch [   46/   60] | d_loss: 1.5509 | g_loss: 1.4527\n",
      "Epoch [   46/   60] | d_loss: 1.0169 | g_loss: 2.6391\n",
      "Epoch [   46/   60] | d_loss: 0.8443 | g_loss: 2.0918\n",
      "Epoch [   47/   60] | d_loss: 1.3626 | g_loss: 2.3408\n",
      "Epoch [   47/   60] | d_loss: 1.5042 | g_loss: 0.7054\n",
      "Epoch [   47/   60] | d_loss: 0.8648 | g_loss: 0.7907\n",
      "Epoch [   47/   60] | d_loss: 0.7174 | g_loss: 1.5547\n",
      "Epoch [   47/   60] | d_loss: 0.9458 | g_loss: 1.1240\n",
      "Epoch [   47/   60] | d_loss: 0.9117 | g_loss: 0.2620\n",
      "Epoch [   47/   60] | d_loss: 1.0759 | g_loss: 2.6221\n",
      "Epoch [   47/   60] | d_loss: 1.5162 | g_loss: 1.5826\n",
      "Epoch [   47/   60] | d_loss: 1.4083 | g_loss: 1.4930\n",
      "Epoch [   47/   60] | d_loss: 1.2823 | g_loss: 2.1761\n",
      "Epoch [   47/   60] | d_loss: 0.7088 | g_loss: 0.9921\n",
      "Epoch [   47/   60] | d_loss: 1.6912 | g_loss: 1.2888\n",
      "Epoch [   47/   60] | d_loss: 1.1490 | g_loss: 0.7742\n",
      "Epoch [   47/   60] | d_loss: 0.7202 | g_loss: 1.0783\n",
      "Epoch [   47/   60] | d_loss: 0.7473 | g_loss: 2.0237\n",
      "Epoch [   47/   60] | d_loss: 0.8580 | g_loss: 0.7375\n",
      "Epoch [   47/   60] | d_loss: 1.5314 | g_loss: 1.3615\n",
      "Epoch [   47/   60] | d_loss: 1.3671 | g_loss: 1.3597\n",
      "Epoch [   47/   60] | d_loss: 0.9171 | g_loss: 0.7192\n",
      "Epoch [   47/   60] | d_loss: 1.4701 | g_loss: 1.5075\n",
      "Epoch [   47/   60] | d_loss: 0.5932 | g_loss: 2.1748\n",
      "Epoch [   47/   60] | d_loss: 1.1701 | g_loss: 2.1130\n",
      "Epoch [   47/   60] | d_loss: 0.9025 | g_loss: 1.8912\n",
      "Epoch [   48/   60] | d_loss: 2.3153 | g_loss: 0.5760\n",
      "Epoch [   48/   60] | d_loss: 0.7138 | g_loss: 1.6546\n",
      "Epoch [   48/   60] | d_loss: 0.9215 | g_loss: 0.6975\n",
      "Epoch [   48/   60] | d_loss: 0.8581 | g_loss: 1.3393\n",
      "Epoch [   48/   60] | d_loss: 1.8134 | g_loss: 1.9797\n",
      "Epoch [   48/   60] | d_loss: 0.6601 | g_loss: 1.2882\n",
      "Epoch [   48/   60] | d_loss: 1.6755 | g_loss: 0.6419\n",
      "Epoch [   48/   60] | d_loss: 2.1429 | g_loss: 2.2951\n",
      "Epoch [   48/   60] | d_loss: 0.7615 | g_loss: 1.8378\n",
      "Epoch [   48/   60] | d_loss: 1.6845 | g_loss: 0.7907\n",
      "Epoch [   48/   60] | d_loss: 0.6824 | g_loss: 2.3799\n",
      "Epoch [   48/   60] | d_loss: 1.0781 | g_loss: 1.4699\n",
      "Epoch [   48/   60] | d_loss: 1.4031 | g_loss: 0.8181\n",
      "Epoch [   48/   60] | d_loss: 1.2159 | g_loss: 0.8657\n",
      "Epoch [   48/   60] | d_loss: 1.0869 | g_loss: 1.9540\n",
      "Epoch [   48/   60] | d_loss: 0.8088 | g_loss: 1.3304\n",
      "Epoch [   48/   60] | d_loss: 1.2965 | g_loss: 0.9106\n",
      "Epoch [   48/   60] | d_loss: 1.2720 | g_loss: 1.3670\n",
      "Epoch [   48/   60] | d_loss: 0.9000 | g_loss: 0.9834\n",
      "Epoch [   48/   60] | d_loss: 0.4885 | g_loss: 0.8465\n",
      "Epoch [   48/   60] | d_loss: 1.8993 | g_loss: 1.7546\n",
      "Epoch [   48/   60] | d_loss: 0.9848 | g_loss: 1.6140\n",
      "Epoch [   48/   60] | d_loss: 0.8042 | g_loss: 0.3791\n",
      "Epoch [   49/   60] | d_loss: 0.5209 | g_loss: 0.7500\n",
      "Epoch [   49/   60] | d_loss: 1.2016 | g_loss: 0.6267\n",
      "Epoch [   49/   60] | d_loss: 1.2486 | g_loss: 1.4515\n",
      "Epoch [   49/   60] | d_loss: 0.8044 | g_loss: 1.0476\n",
      "Epoch [   49/   60] | d_loss: 0.4466 | g_loss: 1.6496\n",
      "Epoch [   49/   60] | d_loss: 1.3836 | g_loss: 1.1346\n",
      "Epoch [   49/   60] | d_loss: 1.2341 | g_loss: 1.0750\n",
      "Epoch [   49/   60] | d_loss: 1.4617 | g_loss: 3.0412\n",
      "Epoch [   49/   60] | d_loss: 0.9940 | g_loss: 1.1265\n",
      "Epoch [   49/   60] | d_loss: 0.9090 | g_loss: 2.0874\n",
      "Epoch [   49/   60] | d_loss: 1.2387 | g_loss: 2.2604\n",
      "Epoch [   49/   60] | d_loss: 0.7545 | g_loss: 1.2872\n",
      "Epoch [   49/   60] | d_loss: 1.1323 | g_loss: 0.7420\n",
      "Epoch [   49/   60] | d_loss: 0.8295 | g_loss: 1.6684\n",
      "Epoch [   49/   60] | d_loss: 1.3409 | g_loss: 1.2028\n",
      "Epoch [   49/   60] | d_loss: 0.8624 | g_loss: 1.9606\n",
      "Epoch [   49/   60] | d_loss: 0.8252 | g_loss: 0.4722\n",
      "Epoch [   49/   60] | d_loss: 0.5771 | g_loss: 0.8290\n",
      "Epoch [   49/   60] | d_loss: 0.8304 | g_loss: 2.0401\n",
      "Epoch [   49/   60] | d_loss: 1.4465 | g_loss: 1.6019\n",
      "Epoch [   49/   60] | d_loss: 1.2194 | g_loss: 1.4639\n",
      "Epoch [   49/   60] | d_loss: 2.0306 | g_loss: 0.6279\n",
      "Epoch [   49/   60] | d_loss: 0.8126 | g_loss: 1.2056\n",
      "Epoch [   50/   60] | d_loss: 0.7993 | g_loss: 0.9188\n",
      "Epoch [   50/   60] | d_loss: 0.5255 | g_loss: 1.1101\n",
      "Epoch [   50/   60] | d_loss: 0.9606 | g_loss: 0.9091\n",
      "Epoch [   50/   60] | d_loss: 1.2607 | g_loss: 0.7162\n",
      "Epoch [   50/   60] | d_loss: 1.1251 | g_loss: 1.1706\n",
      "Epoch [   50/   60] | d_loss: 0.9102 | g_loss: 0.8041\n",
      "Epoch [   50/   60] | d_loss: 0.8827 | g_loss: 0.6790\n",
      "Epoch [   50/   60] | d_loss: 0.7958 | g_loss: 0.6769\n",
      "Epoch [   50/   60] | d_loss: 1.1517 | g_loss: 0.8933\n",
      "Epoch [   50/   60] | d_loss: 1.2264 | g_loss: 0.5589\n",
      "Epoch [   50/   60] | d_loss: 0.5204 | g_loss: 2.2633\n",
      "Epoch [   50/   60] | d_loss: 1.1529 | g_loss: 1.5892\n",
      "Epoch [   50/   60] | d_loss: 0.5602 | g_loss: 2.8454\n",
      "Epoch [   50/   60] | d_loss: 1.7228 | g_loss: 1.3472\n",
      "Epoch [   50/   60] | d_loss: 0.8932 | g_loss: 0.5920\n",
      "Epoch [   50/   60] | d_loss: 0.6617 | g_loss: 1.4669\n",
      "Epoch [   50/   60] | d_loss: 1.2364 | g_loss: 2.0622\n",
      "Epoch [   50/   60] | d_loss: 0.7848 | g_loss: 1.9821\n",
      "Epoch [   50/   60] | d_loss: 0.9672 | g_loss: 0.8087\n",
      "Epoch [   50/   60] | d_loss: 0.7906 | g_loss: 0.8810\n",
      "Epoch [   50/   60] | d_loss: 1.2471 | g_loss: 0.3906\n",
      "Epoch [   50/   60] | d_loss: 1.5864 | g_loss: 1.4406\n",
      "Epoch [   50/   60] | d_loss: 1.5116 | g_loss: 1.0973\n",
      "Generator loss decreased (0.146187 --> 0.089491). Saving model ...\n",
      "Epoch [   51/   60] | d_loss: 1.1706 | g_loss: 1.0682\n",
      "Epoch [   51/   60] | d_loss: 0.8756 | g_loss: 1.9974\n",
      "Epoch [   51/   60] | d_loss: 0.7037 | g_loss: 1.8289\n",
      "Epoch [   51/   60] | d_loss: 0.8195 | g_loss: 0.1831\n",
      "Epoch [   51/   60] | d_loss: 1.3588 | g_loss: 0.5400\n",
      "Epoch [   51/   60] | d_loss: 1.4544 | g_loss: 0.6963\n",
      "Epoch [   51/   60] | d_loss: 0.9782 | g_loss: 1.5086\n",
      "Epoch [   51/   60] | d_loss: 1.9533 | g_loss: 0.5283\n",
      "Epoch [   51/   60] | d_loss: 0.9305 | g_loss: 1.2353\n",
      "Epoch [   51/   60] | d_loss: 0.7749 | g_loss: 2.1576\n",
      "Epoch [   51/   60] | d_loss: 0.7108 | g_loss: 1.5006\n",
      "Epoch [   51/   60] | d_loss: 0.7522 | g_loss: 1.1932\n",
      "Epoch [   51/   60] | d_loss: 0.7279 | g_loss: 0.5822\n",
      "Epoch [   51/   60] | d_loss: 1.1276 | g_loss: 1.7961\n",
      "Epoch [   51/   60] | d_loss: 1.6847 | g_loss: 1.4375\n",
      "Epoch [   51/   60] | d_loss: 0.9527 | g_loss: 1.2458\n",
      "Epoch [   51/   60] | d_loss: 0.6558 | g_loss: 0.9563\n",
      "Epoch [   51/   60] | d_loss: 1.3016 | g_loss: 1.9071\n",
      "Epoch [   51/   60] | d_loss: 0.9573 | g_loss: 2.0816\n",
      "Epoch [   51/   60] | d_loss: 1.4048 | g_loss: 1.2689\n",
      "Epoch [   51/   60] | d_loss: 0.6176 | g_loss: 1.5911\n",
      "Epoch [   51/   60] | d_loss: 1.7459 | g_loss: 1.7485\n",
      "Epoch [   51/   60] | d_loss: 0.9532 | g_loss: 0.6999\n",
      "Epoch [   52/   60] | d_loss: 0.6196 | g_loss: 2.3934\n",
      "Epoch [   52/   60] | d_loss: 0.8854 | g_loss: 1.8917\n",
      "Epoch [   52/   60] | d_loss: 0.9361 | g_loss: 2.1582\n",
      "Epoch [   52/   60] | d_loss: 0.8182 | g_loss: 0.7670\n",
      "Epoch [   52/   60] | d_loss: 1.0163 | g_loss: 1.7848\n",
      "Epoch [   52/   60] | d_loss: 1.2168 | g_loss: 1.5070\n",
      "Epoch [   52/   60] | d_loss: 0.8532 | g_loss: 1.8556\n",
      "Epoch [   52/   60] | d_loss: 1.2133 | g_loss: 1.0625\n",
      "Epoch [   52/   60] | d_loss: 1.0226 | g_loss: 1.1880\n",
      "Epoch [   52/   60] | d_loss: 0.5202 | g_loss: 2.6278\n",
      "Epoch [   52/   60] | d_loss: 1.3689 | g_loss: 0.9572\n",
      "Epoch [   52/   60] | d_loss: 2.0733 | g_loss: 1.0657\n",
      "Epoch [   52/   60] | d_loss: 0.8478 | g_loss: 1.0225\n",
      "Epoch [   52/   60] | d_loss: 0.7983 | g_loss: 0.7124\n",
      "Epoch [   52/   60] | d_loss: 1.0713 | g_loss: 1.8648\n",
      "Epoch [   52/   60] | d_loss: 1.0427 | g_loss: 0.2961\n",
      "Epoch [   52/   60] | d_loss: 0.6688 | g_loss: 1.6353\n",
      "Epoch [   52/   60] | d_loss: 1.9809 | g_loss: 2.8293\n",
      "Epoch [   52/   60] | d_loss: 2.1311 | g_loss: 0.6889\n",
      "Epoch [   52/   60] | d_loss: 0.9998 | g_loss: 1.1810\n",
      "Epoch [   52/   60] | d_loss: 0.8941 | g_loss: 0.6832\n",
      "Epoch [   52/   60] | d_loss: 1.7888 | g_loss: 1.4093\n",
      "Epoch [   52/   60] | d_loss: 0.5323 | g_loss: 0.7581\n",
      "Epoch [   53/   60] | d_loss: 1.2660 | g_loss: 0.7251\n",
      "Epoch [   53/   60] | d_loss: 0.9755 | g_loss: 1.2719\n",
      "Epoch [   53/   60] | d_loss: 1.0812 | g_loss: 1.6286\n",
      "Epoch [   53/   60] | d_loss: 1.7539 | g_loss: 1.0009\n",
      "Epoch [   53/   60] | d_loss: 0.6605 | g_loss: 1.4202\n",
      "Epoch [   53/   60] | d_loss: 0.5874 | g_loss: 0.8647\n",
      "Epoch [   53/   60] | d_loss: 0.8461 | g_loss: 1.7026\n",
      "Epoch [   53/   60] | d_loss: 1.2170 | g_loss: 1.1071\n",
      "Epoch [   53/   60] | d_loss: 1.0743 | g_loss: 1.7346\n",
      "Epoch [   53/   60] | d_loss: 0.9228 | g_loss: 1.2249\n",
      "Epoch [   53/   60] | d_loss: 1.4025 | g_loss: 1.3532\n",
      "Epoch [   53/   60] | d_loss: 0.6072 | g_loss: 0.6932\n",
      "Epoch [   53/   60] | d_loss: 0.6809 | g_loss: 1.8645\n",
      "Epoch [   53/   60] | d_loss: 1.5245 | g_loss: 0.6121\n",
      "Epoch [   53/   60] | d_loss: 1.0027 | g_loss: 0.9087\n",
      "Epoch [   53/   60] | d_loss: 0.9269 | g_loss: 0.4243\n",
      "Epoch [   53/   60] | d_loss: 1.2337 | g_loss: 0.7258\n",
      "Epoch [   53/   60] | d_loss: 0.9611 | g_loss: 1.2024\n",
      "Epoch [   53/   60] | d_loss: 0.7915 | g_loss: 1.6284\n",
      "Epoch [   53/   60] | d_loss: 2.0689 | g_loss: 0.9503\n",
      "Epoch [   53/   60] | d_loss: 1.2162 | g_loss: 1.5347\n",
      "Epoch [   53/   60] | d_loss: 1.3024 | g_loss: 0.7135\n",
      "Epoch [   53/   60] | d_loss: 0.6623 | g_loss: 2.7470\n",
      "Epoch [   54/   60] | d_loss: 2.1311 | g_loss: 1.4787\n",
      "Epoch [   54/   60] | d_loss: 1.1205 | g_loss: 1.7033\n",
      "Epoch [   54/   60] | d_loss: 2.0861 | g_loss: 2.4284\n",
      "Epoch [   54/   60] | d_loss: 0.8299 | g_loss: 1.3414\n",
      "Epoch [   54/   60] | d_loss: 0.6507 | g_loss: 0.8491\n",
      "Epoch [   54/   60] | d_loss: 1.1655 | g_loss: 0.5693\n",
      "Epoch [   54/   60] | d_loss: 0.9985 | g_loss: 0.9992\n",
      "Epoch [   54/   60] | d_loss: 1.0178 | g_loss: 0.7123\n",
      "Epoch [   54/   60] | d_loss: 1.4604 | g_loss: 1.1983\n",
      "Epoch [   54/   60] | d_loss: 1.3538 | g_loss: 1.0174\n",
      "Epoch [   54/   60] | d_loss: 1.5976 | g_loss: 0.5623\n",
      "Epoch [   54/   60] | d_loss: 1.5524 | g_loss: 0.8246\n",
      "Epoch [   54/   60] | d_loss: 1.7728 | g_loss: 0.7495\n",
      "Epoch [   54/   60] | d_loss: 1.2327 | g_loss: 1.6989\n",
      "Epoch [   54/   60] | d_loss: 1.4630 | g_loss: 1.4740\n",
      "Epoch [   54/   60] | d_loss: 1.1198 | g_loss: 0.7272\n",
      "Epoch [   54/   60] | d_loss: 1.5815 | g_loss: 0.6343\n",
      "Epoch [   54/   60] | d_loss: 0.4204 | g_loss: 1.9928\n",
      "Epoch [   54/   60] | d_loss: 1.3559 | g_loss: 2.4676\n",
      "Epoch [   54/   60] | d_loss: 0.9258 | g_loss: 0.9588\n",
      "Epoch [   54/   60] | d_loss: 0.5753 | g_loss: 0.3235\n",
      "Epoch [   54/   60] | d_loss: 0.7866 | g_loss: 0.5933\n",
      "Epoch [   54/   60] | d_loss: 0.6686 | g_loss: 2.0985\n",
      "Discriminator loss decreased (0.545294 --> 0.397821). Saving model ...\n",
      "Epoch [   55/   60] | d_loss: 1.4458 | g_loss: 0.8858\n",
      "Epoch [   55/   60] | d_loss: 1.5437 | g_loss: 0.9024\n",
      "Epoch [   55/   60] | d_loss: 0.8205 | g_loss: 0.9190\n",
      "Epoch [   55/   60] | d_loss: 0.5063 | g_loss: 2.0019\n",
      "Epoch [   55/   60] | d_loss: 0.7558 | g_loss: 0.4586\n",
      "Epoch [   55/   60] | d_loss: 1.2353 | g_loss: 1.1308\n",
      "Epoch [   55/   60] | d_loss: 1.8421 | g_loss: 1.0404\n",
      "Epoch [   55/   60] | d_loss: 1.0882 | g_loss: 1.3189\n",
      "Epoch [   55/   60] | d_loss: 0.9395 | g_loss: 0.5625\n",
      "Epoch [   55/   60] | d_loss: 1.1684 | g_loss: 0.5674\n",
      "Epoch [   55/   60] | d_loss: 0.8424 | g_loss: 1.7572\n",
      "Epoch [   55/   60] | d_loss: 1.2080 | g_loss: 1.7023\n",
      "Epoch [   55/   60] | d_loss: 0.6876 | g_loss: 1.6928\n",
      "Epoch [   55/   60] | d_loss: 0.7357 | g_loss: 1.2088\n",
      "Epoch [   55/   60] | d_loss: 1.5385 | g_loss: 2.0233\n",
      "Epoch [   55/   60] | d_loss: 1.4936 | g_loss: 1.3650\n",
      "Epoch [   55/   60] | d_loss: 0.9237 | g_loss: 1.6918\n",
      "Epoch [   55/   60] | d_loss: 1.7261 | g_loss: 0.7237\n",
      "Epoch [   55/   60] | d_loss: 0.8326 | g_loss: 1.5410\n",
      "Epoch [   55/   60] | d_loss: 1.4054 | g_loss: 1.2783\n",
      "Epoch [   55/   60] | d_loss: 1.5473 | g_loss: 2.4771\n",
      "Epoch [   55/   60] | d_loss: 0.7771 | g_loss: 0.3776\n",
      "Epoch [   55/   60] | d_loss: 1.5712 | g_loss: 0.8947\n",
      "Epoch [   56/   60] | d_loss: 0.6880 | g_loss: 1.3504\n",
      "Epoch [   56/   60] | d_loss: 0.9931 | g_loss: 1.4987\n",
      "Epoch [   56/   60] | d_loss: 2.1468 | g_loss: 1.4513\n",
      "Epoch [   56/   60] | d_loss: 0.6997 | g_loss: 1.3958\n",
      "Epoch [   56/   60] | d_loss: 0.8903 | g_loss: 1.0643\n",
      "Epoch [   56/   60] | d_loss: 0.8795 | g_loss: 0.6404\n",
      "Epoch [   56/   60] | d_loss: 0.6326 | g_loss: 0.7938\n",
      "Epoch [   56/   60] | d_loss: 0.9336 | g_loss: 1.5468\n",
      "Epoch [   56/   60] | d_loss: 1.5519 | g_loss: 0.8276\n",
      "Epoch [   56/   60] | d_loss: 0.8574 | g_loss: 1.8240\n",
      "Epoch [   56/   60] | d_loss: 0.8091 | g_loss: 0.7902\n",
      "Epoch [   56/   60] | d_loss: 1.5027 | g_loss: 0.8113\n",
      "Epoch [   56/   60] | d_loss: 1.8234 | g_loss: 1.1508\n",
      "Epoch [   56/   60] | d_loss: 0.8737 | g_loss: 1.1219\n",
      "Epoch [   56/   60] | d_loss: 0.5325 | g_loss: 0.9774\n",
      "Epoch [   56/   60] | d_loss: 1.3240 | g_loss: 1.7936\n",
      "Epoch [   56/   60] | d_loss: 1.8395 | g_loss: 1.2440\n",
      "Epoch [   56/   60] | d_loss: 1.0319 | g_loss: 2.2631\n",
      "Epoch [   56/   60] | d_loss: 1.2740 | g_loss: 1.6730\n",
      "Epoch [   56/   60] | d_loss: 0.9475 | g_loss: 0.9132\n",
      "Epoch [   56/   60] | d_loss: 0.6890 | g_loss: 1.8553\n",
      "Epoch [   56/   60] | d_loss: 1.1347 | g_loss: 2.1202\n",
      "Epoch [   56/   60] | d_loss: 1.1566 | g_loss: 1.5152\n",
      "Epoch [   57/   60] | d_loss: 0.8980 | g_loss: 1.2671\n",
      "Epoch [   57/   60] | d_loss: 1.0806 | g_loss: 1.3583\n",
      "Epoch [   57/   60] | d_loss: 0.9288 | g_loss: 1.4308\n",
      "Epoch [   57/   60] | d_loss: 0.5754 | g_loss: 0.8696\n",
      "Epoch [   57/   60] | d_loss: 2.0824 | g_loss: 1.0817\n",
      "Epoch [   57/   60] | d_loss: 0.7238 | g_loss: 1.8336\n",
      "Epoch [   57/   60] | d_loss: 1.0341 | g_loss: 1.4617\n",
      "Epoch [   57/   60] | d_loss: 1.1455 | g_loss: 0.8865\n",
      "Epoch [   57/   60] | d_loss: 1.8865 | g_loss: 1.6666\n",
      "Epoch [   57/   60] | d_loss: 1.0658 | g_loss: 0.3527\n",
      "Epoch [   57/   60] | d_loss: 0.8019 | g_loss: 1.0160\n",
      "Epoch [   57/   60] | d_loss: 0.7921 | g_loss: 2.5028\n",
      "Epoch [   57/   60] | d_loss: 0.6895 | g_loss: 0.3797\n",
      "Epoch [   57/   60] | d_loss: 1.0584 | g_loss: 0.7994\n",
      "Epoch [   57/   60] | d_loss: 0.6989 | g_loss: 1.5322\n",
      "Epoch [   57/   60] | d_loss: 1.3818 | g_loss: 1.1510\n",
      "Epoch [   57/   60] | d_loss: 0.7150 | g_loss: 1.0747\n",
      "Epoch [   57/   60] | d_loss: 1.1039 | g_loss: 2.0425\n",
      "Epoch [   57/   60] | d_loss: 1.2439 | g_loss: 1.1046\n",
      "Epoch [   57/   60] | d_loss: 0.9917 | g_loss: 1.9636\n",
      "Epoch [   57/   60] | d_loss: 0.8734 | g_loss: 0.9043\n",
      "Epoch [   57/   60] | d_loss: 1.0012 | g_loss: 2.8494\n",
      "Epoch [   57/   60] | d_loss: 1.2634 | g_loss: 1.0047\n",
      "Epoch [   58/   60] | d_loss: 0.7214 | g_loss: 0.8780\n",
      "Epoch [   58/   60] | d_loss: 0.6073 | g_loss: 0.9438\n",
      "Epoch [   58/   60] | d_loss: 1.6615 | g_loss: 1.7647\n",
      "Epoch [   58/   60] | d_loss: 1.0885 | g_loss: 1.6421\n",
      "Epoch [   58/   60] | d_loss: 0.6961 | g_loss: 2.3654\n",
      "Epoch [   58/   60] | d_loss: 1.0398 | g_loss: 1.9432\n",
      "Epoch [   58/   60] | d_loss: 1.0547 | g_loss: 1.2733\n",
      "Epoch [   58/   60] | d_loss: 1.5983 | g_loss: 1.8522\n",
      "Epoch [   58/   60] | d_loss: 1.2637 | g_loss: 1.5268\n",
      "Epoch [   58/   60] | d_loss: 1.2446 | g_loss: 2.3240\n",
      "Epoch [   58/   60] | d_loss: 1.3248 | g_loss: 0.9785\n",
      "Epoch [   58/   60] | d_loss: 0.9285 | g_loss: 2.0657\n",
      "Epoch [   58/   60] | d_loss: 0.7813 | g_loss: 1.2269\n",
      "Epoch [   58/   60] | d_loss: 2.1570 | g_loss: 1.3212\n",
      "Epoch [   58/   60] | d_loss: 2.2381 | g_loss: 0.3342\n",
      "Epoch [   58/   60] | d_loss: 0.8141 | g_loss: 1.2208\n",
      "Epoch [   58/   60] | d_loss: 0.5591 | g_loss: 1.0456\n",
      "Epoch [   58/   60] | d_loss: 0.7145 | g_loss: 1.3238\n",
      "Epoch [   58/   60] | d_loss: 1.9513 | g_loss: 1.5480\n",
      "Epoch [   58/   60] | d_loss: 0.7739 | g_loss: 0.6507\n",
      "Epoch [   58/   60] | d_loss: 0.7599 | g_loss: 1.2741\n",
      "Epoch [   58/   60] | d_loss: 2.0079 | g_loss: 0.7119\n",
      "Epoch [   58/   60] | d_loss: 1.0208 | g_loss: 1.8021\n",
      "Epoch [   59/   60] | d_loss: 0.9024 | g_loss: 1.4463\n",
      "Epoch [   59/   60] | d_loss: 0.8381 | g_loss: 1.4219\n",
      "Epoch [   59/   60] | d_loss: 1.2392 | g_loss: 1.9231\n",
      "Epoch [   59/   60] | d_loss: 1.1272 | g_loss: 1.5338\n",
      "Epoch [   59/   60] | d_loss: 0.8550 | g_loss: 0.5950\n",
      "Epoch [   59/   60] | d_loss: 0.7857 | g_loss: 0.7880\n",
      "Epoch [   59/   60] | d_loss: 1.2240 | g_loss: 0.8063\n",
      "Epoch [   59/   60] | d_loss: 0.5268 | g_loss: 2.3227\n",
      "Epoch [   59/   60] | d_loss: 1.4182 | g_loss: 1.0656\n",
      "Epoch [   59/   60] | d_loss: 0.9601 | g_loss: 1.5793\n",
      "Epoch [   59/   60] | d_loss: 1.0612 | g_loss: 1.7585\n",
      "Epoch [   59/   60] | d_loss: 0.7139 | g_loss: 2.4912\n",
      "Epoch [   59/   60] | d_loss: 1.1279 | g_loss: 1.2177\n",
      "Epoch [   59/   60] | d_loss: 0.5006 | g_loss: 1.4689\n",
      "Epoch [   59/   60] | d_loss: 1.1086 | g_loss: 1.0528\n",
      "Epoch [   59/   60] | d_loss: 0.5880 | g_loss: 2.8069\n",
      "Epoch [   59/   60] | d_loss: 1.9532 | g_loss: 1.3905\n",
      "Epoch [   59/   60] | d_loss: 0.9024 | g_loss: 2.1394\n",
      "Epoch [   59/   60] | d_loss: 0.7680 | g_loss: 1.2304\n",
      "Epoch [   59/   60] | d_loss: 0.9952 | g_loss: 2.1783\n",
      "Epoch [   59/   60] | d_loss: 1.4988 | g_loss: 1.1937\n",
      "Epoch [   59/   60] | d_loss: 2.2030 | g_loss: 2.1224\n",
      "Epoch [   59/   60] | d_loss: 1.7813 | g_loss: 1.6643\n",
      "Epoch [   60/   60] | d_loss: 1.7595 | g_loss: 1.3242\n",
      "Epoch [   60/   60] | d_loss: 1.1481 | g_loss: 1.5636\n",
      "Epoch [   60/   60] | d_loss: 1.5603 | g_loss: 1.2554\n",
      "Epoch [   60/   60] | d_loss: 0.8580 | g_loss: 2.2456\n",
      "Epoch [   60/   60] | d_loss: 1.2046 | g_loss: 1.1049\n",
      "Epoch [   60/   60] | d_loss: 1.3351 | g_loss: 2.1576\n",
      "Epoch [   60/   60] | d_loss: 0.9341 | g_loss: 1.5797\n",
      "Epoch [   60/   60] | d_loss: 0.9166 | g_loss: 1.0198\n",
      "Epoch [   60/   60] | d_loss: 1.2266 | g_loss: 0.8477\n",
      "Epoch [   60/   60] | d_loss: 2.0271 | g_loss: 0.8090\n",
      "Epoch [   60/   60] | d_loss: 1.0669 | g_loss: 0.2937\n",
      "Epoch [   60/   60] | d_loss: 1.6643 | g_loss: 1.4552\n",
      "Epoch [   60/   60] | d_loss: 0.5488 | g_loss: 1.8976\n",
      "Epoch [   60/   60] | d_loss: 1.0997 | g_loss: 2.5768\n",
      "Epoch [   60/   60] | d_loss: 1.1882 | g_loss: 1.6920\n",
      "Epoch [   60/   60] | d_loss: 1.3501 | g_loss: 1.4520\n",
      "Epoch [   60/   60] | d_loss: 1.3114 | g_loss: 2.4360\n",
      "Epoch [   60/   60] | d_loss: 0.7359 | g_loss: 0.3928\n",
      "Epoch [   60/   60] | d_loss: 0.6853 | g_loss: 2.1082\n"
     ]
    }
   ],
   "source": [
    "# set number of epochs \n",
    "n_epochs = 60\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# call training function\n",
    "losses = train(D, G, n_epochs=n_epochs,print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO, load saved models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training loss\n",
    "\n",
    "Plot the training losses for the generator and discriminator, recorded after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Discriminator', alpha=0.5)\n",
    "plt.plot(losses.T[1], label='Generator', alpha=0.5)\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generator samples from training\n",
    "\n",
    "View samples of images from the generator, and answer a question about the strengths and weaknesses of your trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for viewing a list of passed in sample images\n",
    "def view_samples(epoch, samples):\n",
    "    fig, axes = plt.subplots(figsize=(16,4), nrows=2, ncols=8, sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
    "        img = img.detach().cpu().numpy()\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        img = ((img + 1)*255 / (2)).astype(np.uint8)\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.reshape((32,32,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load samples from generator, taken while training\n",
    "with open('train_samples.pkl', 'rb') as f:\n",
    "    samples = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = view_samples(-1, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What do you notice about your generated samples and how might you improve this model?\n",
    "When you answer this question, consider the following factors:\n",
    "* The dataset is biased; it is made of \"celebrity\" faces that are mostly white\n",
    "* Model size; larger models have the opportunity to learn more features in a data feature space\n",
    "* Optimization strategy; optimizers and number of epochs affect your final result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** (Write your answer in this cell)\n",
    "\n",
    "Even though the generated samples are pixelated, overall they look good, especially the ones that are facing forward and not the ones with angles. That being said, it looks like the Generator cannot make a sample that has a hat.\n",
    "\n",
    "I think if the source images are in better quality, say 64x64 or 128x128 then the generator might generate better samples.\n",
    "\n",
    "I did 2 attempts and each with 20 epocs, first with 3 conv layers in Discriminator and Generator and second with 4 conv layers. I wanted to see if having an extra layer will improve feature extractions, hence improving the Generator.\n",
    "\n",
    "The first attempt:\n",
    "\n",
    "```\n",
    "// After epoch 9, it couldn't bring the loss down anymore\n",
    "Generator loss decreased (0.494636 --> 0.389061).\n",
    "Discriminator loss decreased (0.356189 --> 0.346459).\n",
    "```\n",
    "\n",
    "The second attempt:\n",
    "\n",
    "```\n",
    "// After epoch 12, it couldn't bring the loss down anymore\n",
    "Generator loss decreased (0.478706 --> 0.255390).\n",
    "Discriminator loss decreased (0.172448 --> 0.132009).\n",
    "```\n",
    "\n",
    "#### The result:\n",
    "\n",
    "![](samples_code_review_first_submission.png?raw=true)\n",
    "\n",
    "\n",
    "### Update (code review)\n",
    "I'm glad to receive feedback to improve my project. \n",
    "\n",
    "> 1. The batch size as 128 is quite high. Using a large value of batch size makes the gradients become less noisy and it won't be able to improve much.\n",
    "There's a tradeoff of using a small batch size too. A very low batch size can make the gradients unstable and we will have to lower down the learning rate.\n",
    "I encourage you to try using batch size in the range of 16-64.\n",
    "\n",
    "> 2. You have used the hyperparameter values that we used in DCGAN project. Consider tuning the hyperparamter values. Try tuning the learning rate. It's noticed that network performs better with lower beta1.\n",
    "\n",
    "> 3. The generated images are improving but there's still some space for improvement. I encourage you to try working on the things mentioned above and retrain the model.\n",
    "\n",
    "The following are the results based on the feedback.\n",
    "\n",
    "#### The first attempt:\n",
    "\n",
    "```python\n",
    "# I changed the batch size from 128 to 20\n",
    "batch_size = 20\n",
    "# I used BCEWithLogitsLoss and label smoothening in real_loss and fake_loss function as suggested.\n",
    "# I added 2 (two) extra conv layer in the Discrimator as suggested.\n",
    "# I changed the learning rate from 0.0002 to 0.0003 and beta1 from 0.5 to 0.4\n",
    "lr = 0.0003\n",
    "beta1=0.4\n",
    "```\n",
    "\n",
    "#### The result:\n",
    "\n",
    "![](samples_code_review_attempt_ONE.png?raw=true)\n",
    "\n",
    "\n",
    "#### The second attempt:\n",
    "\n",
    "```python\n",
    "# I changed the batch size from 128 to 40\n",
    "batch_size = 40\n",
    "# I used BCEWithLogitsLoss and label smoothening in real_loss and fake_loss function as suggested.\n",
    "# I added 3 (three) extra conv layer in the Discrimator as suggested.\n",
    "# I changed the learning rate from 0.0002 to 0.0003 and beta1 from 0.5 to 0.4\n",
    "lr = 0.0003\n",
    "beta1=0.45\n",
    "```\n",
    "\n",
    "#### The result:\n",
    "\n",
    "![](samples_code_review_attempt_TWO.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_face_generation.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\". Include the \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
